{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BQflUKhjIKNp"
      },
      "source": [
        "### Notes \n",
        "\n",
        "T5 Paper: https://arxiv.org/pdf/1910.10683.pdf\n",
        "\n",
        "T5 Tokenizer: https://github.com/huggingface/transformers/blob/master/src/transformers/tokenization_t5.py\n",
        "\n",
        "Important Tasks: https://docs.google.com/document/d/1weIZM6QTlnitpPQmpg-WeV2RW70TnYmDuogBQPr5mB0/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOmiOta6MJp",
        "colab_type": "code",
        "outputId": "f6a06e8f-8e2e-4a5d-bff8-3303d7cf2f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#installation step\n",
        "!pip install transformers\n",
        "!pip install t5\n",
        "!pip install sentencepiece\n",
        "!pip install bpemb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
            "\r\u001b[K     |▌                               | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 368kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 419kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 450kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 481kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 501kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 532kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 563kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 614kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 15.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 19.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=9ba0c66645692d6a9e6c368f76aa6082cf15da4353ca4b6b7deb66f7025ca9c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.9.0\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/93/e25d0043ece218a94d14f710c553bbcc7974d2ff169b4aa8f8d1423dca95/t5-0.5.0-py3-none-any.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5) (0.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5) (1.0.3)\n",
            "Collecting six>=1.14\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5) (2.8.0)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/35/b87b84648f84b9021df3407422d3cf9afdcbb9b087d2bf293fe72557b7a5/tensorflow_text-2.1.1-cp36-cp36m-manylinux1_x86_64.whl (8.3MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3MB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from t5) (2.9.0)\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/42/df5f05f2124f9d1b6e16b88c518f04a7d282d77daf3113ba548baadc4ce5/tfds_nightly-3.1.0.dev202005100106-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5) (1.5.0+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5) (1.18.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5) (0.9.0)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[?25hCollecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/32/ceaf1549586ccfeaf7840a166876be358bd78ab2fdd152b17c5600ed7888/mesh_tensorflow-0.1.13-py3-none-any.whl (292kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 60.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5) (1.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from t5) (0.1.86)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->t5) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->t5) (2018.9)\n",
            "Collecting tensorflow<2.2,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (3.0.12)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (19.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (2.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (1.12.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (0.3.1.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (1.1.0)\n",
            "Collecting tensorflow-metadata<0.16,>=0.15\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/0c/afb81ea6998f6e26521671585d1cd9d3f7945a8b9834764e91757453dc25/tensorflow_metadata-0.15.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5) (0.14.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->t5) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-datasets; extra == \"transformer\" in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (2.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 60.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5) (2.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5) (7.1.2)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata<0.16,>=0.15->tfds-nightly->t5) (1.51.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly->t5) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (2.10.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=0f14ecc7a7fd3d0cd81785a1187a8295f09d1a8619b46f1c5bd11e19dc6a25c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, rouge-score, gast, tensorboard, tensorflow-estimator, tensorflow, tensorflow-text, tensorflow-metadata, tfds-nightly, portalocker, sacrebleu, mesh-tensorflow, t5\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "  Found existing installation: tensorflow-metadata 0.21.2\n",
            "    Uninstalling tensorflow-metadata-0.21.2:\n",
            "      Successfully uninstalled tensorflow-metadata-0.21.2\n",
            "Successfully installed gast-0.2.2 mesh-tensorflow-0.1.13 portalocker-1.7.0 rouge-score-0.0.3 sacrebleu-1.4.9 six-1.14.0 t5-0.5.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tensorflow-metadata-0.15.2 tensorflow-text-2.1.1 tfds-nightly-3.1.0.dev202005100106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.86)\n",
            "Collecting bpemb\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb) (1.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bpemb) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb) (0.1.86)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (2.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.14.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (1.13.3)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (1.16.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim->bpemb) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim->bpemb) (2.8.1)\n",
            "Installing collected packages: bpemb\n",
            "Successfully installed bpemb-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxIQAzEiK_oH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc2aaaef-c602-4026-bb7d-03e2ccbdec22"
      },
      "source": [
        "#creating the folders \n",
        "!mkdir data/\n",
        "!mkdir data/AD_NMT-master\n",
        "!mkdir data/train/\n",
        "!mkdir data/test/\n",
        "!mkdir data/val/\n",
        "#fetching the pkl files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW' -O data/AD_NMT-master/english-Arabic-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1' -O data/AD_NMT-master/english-Arabic-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e' -O data/AD_NMT-master/english-Arabic-train.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV' -O data/AD_NMT-master/LAV-MSA-2-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3' -O data/AD_NMT-master/LAV-MSA-2-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw' -O data/AD_NMT-master/LAV-MSA-2-train.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16' -O data/AD_NMT-master/Magribi_MSA-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l' -O data/AD_NMT-master/Magribi_MSA-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ' -O data/AD_NMT-master/Magribi_MSA-train.pkl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-11 00:44:11--  https://docs.google.com/uc?export=download&id=1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.69.138, 74.125.69.102, 74.125.69.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.69.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ums068j8r195s8d0e1kac2q4a367b8hs/1589157825000/16970776037313924126/*/1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:11--  https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ums068j8r195s8d0e1kac2q4a367b8hs/1589157825000/16970776037313924126/*/1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW?e=download\n",
            "Resolving doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 955428 (933K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 933.04K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-05-11 00:44:12 (115 MB/s) - ‘data/AD_NMT-master/english-Arabic-both.pkl’ saved [955428/955428]\n",
            "\n",
            "--2020-05-11 00:44:12--  https://docs.google.com/uc?export=download&id=1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.212.138, 172.217.212.102, 172.217.212.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.212.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lhssalrbsiimv4bqtkhbmt6nr60g90ek/1589157825000/16970776037313924126/*/1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:12--  https://doc-14-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lhssalrbsiimv4bqtkhbmt6nr60g90ek/1589157825000/16970776037313924126/*/1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1?e=download\n",
            "Resolving doc-14-2s-docs.googleusercontent.com (doc-14-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-14-2s-docs.googleusercontent.com (doc-14-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95497 (93K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>]  93.26K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-05-11 00:44:13 (144 MB/s) - ‘data/AD_NMT-master/english-Arabic-test.pkl’ saved [95497/95497]\n",
            "\n",
            "--2020-05-11 00:44:13--  https://docs.google.com/uc?export=download&id=1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.129.138, 74.125.129.100, 74.125.129.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.129.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jcdrs6hqg3snnqm5pgl5kvqntmop38km/1589157825000/16970776037313924126/*/1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:14--  https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jcdrs6hqg3snnqm5pgl5kvqntmop38km/1589157825000/16970776037313924126/*/1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e?e=download\n",
            "Resolving doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 859172 (839K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 839.04K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2020-05-11 00:44:14 (160 MB/s) - ‘data/AD_NMT-master/english-Arabic-train.pkl’ saved [859172/859172]\n",
            "\n",
            "--2020-05-11 00:44:16--  https://docs.google.com/uc?export=download&id=1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.214.102, 172.217.214.138, 172.217.214.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.214.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/m23helb4cbv5he7tccen185f1dpbhlvb/1589157825000/16970776037313924126/*/1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:17--  https://doc-00-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/m23helb4cbv5he7tccen185f1dpbhlvb/1589157825000/16970776037313924126/*/1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV?e=download\n",
            "Resolving doc-00-2s-docs.googleusercontent.com (doc-00-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-00-2s-docs.googleusercontent.com (doc-00-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.33M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2020-05-11 00:44:17 (246 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-both.pkl’ saved [2447014]\n",
            "\n",
            "--2020-05-11 00:44:17--  https://docs.google.com/uc?export=download&id=1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.129.138, 74.125.129.101, 74.125.129.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.129.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p37a92ks8ijiec6hp5a2u9nl9bgu0nat/1589157825000/16970776037313924126/*/1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:18--  https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p37a92ks8ijiec6hp5a2u9nl9bgu0nat/1589157825000/16970776037313924126/*/1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3?e=download\n",
            "Resolving doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 304332 (297K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 297.20K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-05-11 00:44:18 (150 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-test.pkl’ saved [304332/304332]\n",
            "\n",
            "--2020-05-11 00:44:19--  https://docs.google.com/uc?export=download&id=1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw\n",
            "Resolving docs.google.com (docs.google.com)... 209.85.200.113, 209.85.200.138, 209.85.200.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|209.85.200.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d9bd193fo1lp9lv5jj41v978eg1cr5g4/1589157825000/16970776037313924126/*/1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:19--  https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d9bd193fo1lp9lv5jj41v978eg1cr5g4/1589157825000/16970776037313924126/*/1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw?e=download\n",
            "Resolving doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.04M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2020-05-11 00:44:19 (231 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-train.pkl’ saved [2141923]\n",
            "\n",
            "--2020-05-11 00:44:20--  https://docs.google.com/uc?export=download&id=1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.129.138, 74.125.129.101, 74.125.129.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.129.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r7baj2784lnf0hlj3fsoaoke7jho0itm/1589157825000/16970776037313924126/*/1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:21--  https://doc-04-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/r7baj2784lnf0hlj3fsoaoke7jho0itm/1589157825000/16970776037313924126/*/1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16?e=download\n",
            "Resolving doc-04-2s-docs.googleusercontent.com (doc-04-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-04-2s-docs.googleusercontent.com (doc-04-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.81M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-05-11 00:44:21 (256 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-both.pkl’ saved [2944107]\n",
            "\n",
            "--2020-05-11 00:44:21--  https://docs.google.com/uc?export=download&id=1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.212.113, 172.217.212.100, 172.217.212.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.212.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/18msub00imll5b807p0g27lh4gd87146/1589157825000/16970776037313924126/*/1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:22--  https://doc-0o-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/18msub00imll5b807p0g27lh4gd87146/1589157825000/16970776037313924126/*/1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l?e=download\n",
            "Resolving doc-0o-2s-docs.googleusercontent.com (doc-0o-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-0o-2s-docs.googleusercontent.com (doc-0o-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290840 (284K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 284.02K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-05-11 00:44:22 (152 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-test.pkl’ saved [290840/290840]\n",
            "\n",
            "--2020-05-11 00:44:22--  https://docs.google.com/uc?export=download&id=1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.120.100, 108.177.120.139, 108.177.120.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.120.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/86t418eeov5sm0ds9fueni7l37p0p1ge/1589157825000/16970776037313924126/*/1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-11 00:44:22--  https://doc-0s-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/86t418eeov5sm0ds9fueni7l37p0p1ge/1589157825000/16970776037313924126/*/1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ?e=download\n",
            "Resolving doc-0s-2s-docs.googleusercontent.com (doc-0s-2s-docs.googleusercontent.com)... 74.125.202.132, 2607:f8b0:4001:c06::84\n",
            "Connecting to doc-0s-2s-docs.googleusercontent.com (doc-0s-2s-docs.googleusercontent.com)|74.125.202.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.53M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-11 00:44:23 (117 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-train.pkl’ saved [2652508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-WzhRv4mIKNq",
        "colab": {}
      },
      "source": [
        "#James Chartouni\n",
        "#Joey Park\n",
        "#Raef Khan\n",
        "\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os, io, glob\n",
        "import functools\n",
        "\n",
        "import sentencepiece as spm\n",
        "from bpemb import BPEmb\n",
        "\n",
        "import transformers\n",
        "import t5\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF7j2_wBLHR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5e1cf822-7b6b-4c0a-9f75-94cbbcc41e7e"
      },
      "source": [
        "print(\"Installing dependencies...\")\n",
        "%tensorflow_version 2.x\n",
        "!pip install -q t5\n",
        "\n",
        "import functools\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "BASE_DIR = \"gs://t5at\" #@param { type: \"string\" }\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  print(\"Setting up GCS access...\")\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth('/device:CPU:0')\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "Setting up GCS access...\n",
            "Running on TPU: grpc://10.49.75.2:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxCLgMZ2ns4b",
        "colab_type": "text"
      },
      "source": [
        "##Initial Loading from Pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T67vZ0Nv4-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aha0xureIKNw",
        "outputId": "fab3d0b3-7652-4ba0-f447-706b3f432527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls data/AD_NMT-master"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english-Arabic-both.pkl   LAV-MSA-2-both.pkl   Magribi_MSA-both.pkl\n",
            "english-Arabic-test.pkl   LAV-MSA-2-test.pkl   Magribi_MSA-test.pkl\n",
            "english-Arabic-train.pkl  LAV-MSA-2-train.pkl  Magribi_MSA-train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWKnGRlLIKN9",
        "colab": {}
      },
      "source": [
        "file_path = 'data/AD_NMT-master/'\n",
        "\n",
        "with open(file_path + \"english-Arabic-train.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_trainval = pickle.load(handle)\n",
        "\n",
        "with open(file_path + \"english-Arabic-test.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_test = pickle.load(handle)\n",
        "\n",
        "with open(file_path + \"english-Arabic-both.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_both = pickle.load(handle) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-train.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_trainval = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-test.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_test = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-both.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_both = pickle.load(handle) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(file_path + \"Magribi_MSA-train.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_trainval = pickle.load(handle) \n",
        "    \n",
        "with open(file_path + \"Magribi_MSA-test.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_test = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"Magribi_MSA-both.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_both = pickle.load(handle) \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ch3APJadIKOH",
        "outputId": "354288e2-e795-48bb-f017-19ac63b88002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#few dataset examples\n",
        "print(data_MSA_English_both[0:5])\n",
        "print(data_LAV_MSA_both[0:5])\n",
        "\n",
        "#print length of train + val dataset, print length of both (train + val) + test\n",
        "print(len(data_MSA_English_trainval))\n",
        "print(len(data_MSA_English_both))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Tom was also there', 'كان توم هنا ايضا'], ['That old woman lives by herself', 'تلك المراة العجوز تسكن بمفردها'], ['He went abroad for the purpose of studying English', 'سافر خارج البلد ليتعلم الانجليزية'], ['There is a fork missing', 'هناك شوكة ناقصة'], [\"I don't know this game\", 'لا اعرف هذه اللعبة']]\n",
            "[['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش', 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة'], ['روح بوشك و فتول عاليسار', 'اذهب تقدم و استدر يسارا'], ['لا لا لازم انه يكون عندك موضوع ما في اشي', ' لا لا يجب ان يكون لديك موضوع هذا ضروري'], ['اوعي تبعدي من هون بلاش تضيعي ', 'لا تبتعد عن هنا حتى لا تفقد الطريق '], ['قصدي صراحة يما انا كمان كرهته من يوم ما عملتيه زي ما بتعمله خالتي كرهته و صرت ما باطيقه بالمرة', 'اقصد صراحة يا امي انا ايضا كرهته من يوم حضرته مثلما تحضره خالتي كرهته و اصبحت لا اطيقه ابدا']]\n",
            "9000\n",
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "irQQ9E_7IKOM"
      },
      "source": [
        "## Prepare Datasets\n",
        "\n",
        "example: https://iwslt2010.fbk.eu/node/32/\n",
        "\n",
        "We need to take our training and test sets from the pkl files and create new .txt files that are formatted so that the standard torchtext Dataset class can read them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "raw",
        "id": "ikpu9B5dIKON"
      },
      "source": [
        "Data format:\n",
        "each line consists of three fields divided by the character '\\'\n",
        "sentences consisting of words divided by single spaces\n",
        "format: <SENTENCE_ID>\\<PARAPHRASE_ID>\\<TEXT>\n",
        "Field_1: sentence ID\n",
        "Field_2: paraphrase ID\n",
        "Field_3: MT develop sentence / reference translation\n",
        "Text input example:\n",
        "DEV_001\\01\\This is the first develop sentence.\n",
        "DEV_002\\01\\This is the second develop sentence.\n",
        "Reference translation example:\n",
        "DEV_001\\01\\1st reference translation for 1st input\n",
        "DEV_001\\02\\2nd reference translation for 1st input\n",
        "...\n",
        "DEV_002\\01\\1st reference translation for 2nd input\n",
        "DEV_002\\02\\2nd reference translation for 2nd input\n",
        "...\n",
        "Languages:\n",
        "Arabic-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n",
        "IWSLT05 testset: 506 sentences, 16 reference translations\n",
        "IWSLT07 testset: 489 sentences, 6 reference translations\n",
        "IWSLT08 testset: 507 sentences, 16 reference translations\n",
        "French-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n",
        "IWSLT05 testset: 506 sentences, 16 reference translations\n",
        "Turkish-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7wcnDJDKwqED",
        "outputId": "08158f2b-ff04-4191-e5ea-d12abb5b002e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls data/AD_NMT-master/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english-Arabic-both.pkl   LAV-MSA-2-both.pkl   Magribi_MSA-both.pkl\n",
            "english-Arabic-test.pkl   LAV-MSA-2-test.pkl   Magribi_MSA-test.pkl\n",
            "english-Arabic-train.pkl  LAV-MSA-2-train.pkl  Magribi_MSA-train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lp7ncVY6wqET",
        "colab": {}
      },
      "source": [
        "#splits the train dataset into train and validation sets, define test set as datafile\n",
        "msa_en_train, msa_en_val = train_test_split(data_MSA_English_trainval, test_size=.2)\n",
        "msa_en_test = data_MSA_English_test\n",
        "\n",
        "lav_msa_train, lav_msa_val = train_test_split(data_LAV_MSA_trainval, test_size=.2)\n",
        "lav_msa_test = data_LAV_MSA_test\n",
        "\n",
        "mag_msa_train, mag_msa_val = train_test_split(data_Magribi_MSA_trainval, test_size=.2)\n",
        "mag_msa_test = data_Magribi_MSA_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Ue2fSILwqEW",
        "outputId": "42547903-942f-4a90-866a-73ec93677a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(len(msa_en_train))\n",
        "print(len(msa_en_val))\n",
        "\n",
        "print(len(lav_msa_train))\n",
        "print(len(lav_msa_val))\n",
        "\n",
        "print(len(mag_msa_train))\n",
        "print(len(mag_msa_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7200\n",
            "1800\n",
            "11044\n",
            "2761\n",
            "14188\n",
            "3548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3bWU46TIKOb",
        "colab": {}
      },
      "source": [
        "file_path = 'data/'\n",
        "\n",
        "def list_to_csv(ds, src='msa', trg='en', datatype=''):\n",
        "    src_formatted = datatype + '_' + src + '_' + trg + '.' + 'csv'\n",
        "    \n",
        "    with open(file_path + datatype + \"/\" + src_formatted, 'wt') as csv:\n",
        "        for i, arr in enumerate(ds):\n",
        "            csv.write(arr[1] + ',' + arr[0] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AqwDB9BuKEnV",
        "colab": {}
      },
      "source": [
        "list_to_csv(msa_en_train, 'msa', 'en', 'train')\n",
        "list_to_csv(msa_en_val, 'msa', 'en', 'val')\n",
        "list_to_csv(msa_en_test, 'msa', 'en', 'test')\n",
        "\n",
        "list_to_csv(lav_msa_train, 'lav', 'msa', 'train')\n",
        "list_to_csv(lav_msa_val, 'lav', 'msa', 'val')\n",
        "list_to_csv(lav_msa_test, 'lav', 'msa', 'test')\n",
        "\n",
        "list_to_csv(mag_msa_train, 'mag', 'msa', 'train')\n",
        "list_to_csv(mag_msa_val, 'mag', 'msa', 'val')\n",
        "list_to_csv(mag_msa_test, 'mag', 'msa', 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_9vDatSOhO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a24eb2ca-807c-40a9-dffc-930d7d5f857a"
      },
      "source": [
        "!gsutil -m cp -r \"data/*\" $DATA_DIR"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://data/val/val_msa_en.csv [Content-Type=text/csv]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/val/val_mag_msa.csv [Content-Type=text/csv]...\n",
            "Copying file://data/train/train_mag_msa.csv [Content-Type=text/csv]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \r/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/train/train_msa_en.csv [Content-Type=text/csv]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/train/train_lav_msa.csv [Content-Type=text/csv]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/english-Arabic-test.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/Magribi_MSA-test.pkl [Content-Type=application/octet-stream]...\n",
            "Copying file://data/AD_NMT-master/english-Arabic-both.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \r/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/english-Arabic-train.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/Magribi_MSA-train.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/LAV-MSA-2-test.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/AD_NMT-master/LAV-MSA-2-train.pkl [Content-Type=application/octet-stream]...\n",
            "/ [0/18 files][    0.0 B/ 17.0 MiB]   0% Done                                   \rCopying file://data/val/val_lav_msa.csv [Content-Type=text/csv]...\n",
            "/ [0/18 files][121.0 KiB/ 17.0 MiB]   0% Done                                   \rCopying file://data/test/test_lav_msa.csv [Content-Type=text/csv]...\n",
            "Copying file://data/test/test_msa_en.csv [Content-Type=text/csv]...\n",
            "Copying file://data/test/test_mag_msa.csv [Content-Type=text/csv]...\n",
            "Copying file://data/AD_NMT-master/Magribi_MSA-both.pkl [Content-Type=application/octet-stream]...\n",
            "Copying file://data/AD_NMT-master/LAV-MSA-2-both.pkl [Content-Type=application/octet-stream]...\n",
            "/ [18/18 files][ 17.0 MiB/ 17.0 MiB] 100% Done                                  \n",
            "Operation completed over 18 objects/17.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19T4J6mOmKff",
        "colab_type": "text"
      },
      "source": [
        "##Loading MultiBPemb: Multilingual BPEmb Sentencepiece Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AgOklFxmWEr",
        "colab_type": "code",
        "outputId": "81609b16-8625-452c-e11d-dc25072a3c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "multibpemb = BPEmb(lang=\"multi\", vs=1000000, dim=300)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHAuzNW1eIh",
        "colab_type": "text"
      },
      "source": [
        "##Tensor Processing + Add to TaskRegistry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVVzdeAZd0x",
        "colab_type": "text"
      },
      "source": [
        "### English to Arabic Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWnZcYI_491p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msa_en_split_csv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"train/train_msa_en.csv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"val/val_msa_en.csv\")\n",
        "}\n",
        "msa_en_example_count = {\n",
        "    \"train\": 7200,\n",
        "    \"validation\": 1800\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2e3cM_wP_M8",
        "colab_type": "code",
        "outputId": "e66c9416-7074-4701-d8aa-9e29b3211b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def msa_en_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(msa_en_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(msa_en_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b'\\xd9\\x85\\xd9\\x86 \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x85\\xd9\\x83\\xd9\\x86 \\xd8\\xa7\\xd9\\x84\\xd8\\xa7 \\xd8\\xaa\\xd8\\xa7\\xd8\\xaa\\xd9\\x8a \\xd8\\xba\\xd8\\xaf\\xd8\\xa7', 'target': b'She may not come here tomorrow'}\n",
            "{'source': b'\\xd8\\xa7\\xd9\\x86\\xd8\\xaa\\xd8\\xa8\\xd9\\x87! \\xd9\\x87\\xd9\\x86\\xd8\\xa7\\xd9\\x83 \\xd8\\xad\\xd9\\x81\\xd8\\xb1\\xd8\\xa9 \\xd9\\x83\\xd8\\xa8\\xd9\\x8a\\xd8\\xb1\\xd8\\xa9 \\xd9\\x87\\xd9\\x86\\xd8\\xa7\\xd9\\x83', 'target': b\"Watch out! There's a big hole there\"}\n",
            "{'source': b'\\xd8\\xa7\\xd8\\xb9\\xd9\\x8a\\xd8\\xaf\\xd9\\x87 \\xd8\\xa7\\xd9\\x84\\xd9\\x8a', 'target': b'Bring it back to me'}\n",
            "{'source': b'\\xd8\\xaf\\xd8\\xa7\\xd8\\xa6\\xd9\\x85\\xd8\\xa7 \\xd9\\x85\\xd8\\xa7 \\xd8\\xa7\\xd8\\xb5\\xd8\\xa7\\xd8\\xaf\\xd9\\x81 \\xd8\\xb3\\xd9\\x8a\\xd8\\xa7\\xd8\\xad \\xd9\\x8a\\xd8\\xa7\\xd8\\xa8\\xd8\\xa7\\xd9\\x86\\xd9\\x8a\\xd9\\x8a\\xd9\\x86 \\xd9\\x81\\xd9\\x8a \\xd9\\x87\\xd8\\xb0\\xd9\\x87 \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x86\\xd8\\xb7\\xd9\\x82\\xd8\\xa9 ', 'target': b'We often come across Japanese tourists in this area'}\n",
            "{'source': b'\\xd8\\xaf\\xd8\\xae\\xd9\\x84\\xd8\\xaa \\xd9\\x85\\xd8\\xa7\\xd8\\xb1\\xd9\\x8a', 'target': b'Mary came in'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1GXED2IO3pE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def msa_en_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate MSA to English: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag6soPRLhcwY",
        "colab_type": "code",
        "outputId": "dfd175e6-8133-4044-b0c3-bde77b4810f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filepath = str(multibpemb.model_file)\n",
        "print(filepath)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.cache/bpemb/multi/multi.wiki.bpe.vs1000000.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W6j-SDXcNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"msa_en_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"msa_en_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=msa_en_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[msa_en_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path= filepath, #str(multibpemb.model_file), #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    #num_input_examples=num_nq_examples\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGr8wt7naDRL",
        "colab_type": "text"
      },
      "source": [
        "###Levantine to MSA Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3A3wQdjagH6",
        "colab": {}
      },
      "source": [
        "lav_msa_split_csv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"train/train_lav_msa.csv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"val/val_lav_msa.csv\")\n",
        "}\n",
        "lav_msa_example_count = {\n",
        "    \"train\": 11044,\n",
        "    \"validation\": 2761\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2d4b2130-dfea-4a5b-fa68-1ee340a86a9c",
        "id": "xCK_j-9BagH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def lav_msa_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(lav_msa_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(lav_msa_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b'\\xd8\\xaa\\xd9\\x85\\xd8\\xab\\xd9\\x84 \\xd9\\x81\\xd9\\x8a\\xd9\\x87 \\xd8\\xac\\xd9\\x88\\xd8\\xa7\\xd9\\x87\\xd8\\xb1', 'target': b'\\xd8\\xa8\\xd8\\xaa\\xd9\\x85\\xd8\\xab\\xd9\\x84 \\xd9\\x81\\xd9\\x8a\\xd9\\x87 \\xd8\\xac\\xd9\\x88\\xd8\\xa7\\xd9\\x87\\xd8\\xb1'}\n",
            "{'source': b'\\xd9\\x81\\xd9\\x87\\xd9\\x88 \\xd8\\xa7\\xd8\\xb0\\xd8\\xa7\\xd8\\xb5\\xd8\\xa7\\xd8\\xb1 \\xd8\\xb4\\xd8\\xb1\\xd8\\xb9\\xd9\\x8a\\xd8\\xa7 \\xd9\\x88 \\xd9\\x85\\xd8\\xb4\\xd8\\xb1\\xd9\\x88\\xd8\\xb9\\xd8\\xa7', 'target': b'\\xd9\\x87\\xd9\\x88 \\xd8\\xb5\\xd8\\xa7\\xd8\\xb1 \\xd9\\x84\\xd9\\x83\\xd9\\x86 \\xd8\\xb4\\xd8\\xb1\\xd8\\xb9\\xd9\\x8a \\xd9\\x88 \\xd9\\x85\\xd8\\xb4\\xd8\\xb1\\xd9\\x88\\xd8\\xb9'}\n",
            "{'source': b'\\xd8\\xad\\xd9\\x82\\xd8\\xa7  \\xd8\\xb9\\xd9\\x82\\xd8\\xaf \\xd9\\x84\\xd8\\xaf\\xd9\\x89 \\xd8\\xa7\\xd9\\x84\\xd8\\xae\\xd9\\x88\\xd8\\xa7\\xd8\\xb5', 'target': b'\\xd8\\xb9\\xd9\\x86\\xd8\\xac\\xd8\\xaf \\xd8\\xb9\\xd9\\x82\\xd8\\xaf \\xd8\\xb9\\xd9\\x86\\xd8\\xaf \\xd8\\xa7\\xd9\\x84\\xd8\\xae\\xd8\\xa7\\xd8\\xb5'}\n",
            "{'source': b'\\xd9\\x84\\xd9\\x83\\xd9\\x86 \\xd9\\x81\\xd9\\x8a \\xd9\\x85\\xd8\\xaf\\xd8\\xb1\\xd8\\xb3\\xd8\\xa9 \\xd9\\x88\\xd8\\xb7\\xd9\\x86\\xd9\\x8a\\xd8\\xa9', 'target': b'\\xd8\\xa8\\xd8\\xb3 \\xd8\\xa8\\xd9\\x85\\xd8\\xaf\\xd8\\xb1\\xd8\\xb3\\xd8\\xa9 \\xd9\\x88\\xd8\\xb7\\xd9\\x86\\xd9\\x8a\\xd8\\xa9'}\n",
            "{'source': b'\\xd9\\x86\\xd8\\xad\\xd9\\x86 \\xd9\\x86\\xd8\\xb4\\xd8\\xa7\\xd9\\x87\\xd8\\xaf \\xd9\\x82\\xd9\\x86\\xd8\\xa7\\xd8\\xa9 \\xd8\\xa7\\xd9\\x84\\xd8\\xac\\xd8\\xb2\\xd9\\x8a\\xd8\\xb1\\xd8\\xa9 \\xd8\\xb7\\xd9\\x88\\xd8\\xa7\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd9\\x88\\xd9\\x85 ', 'target': b'\\xd9\\x83\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd9\\x88\\xd9\\x85 \\xd9\\x88 \\xd9\\x86\\xd8\\xad\\xd9\\x86\\xd8\\xa7 \\xd8\\xb9\\xd9\\x85 \\xd9\\x86\\xd8\\xaa\\xd9\\x81\\xd8\\xb1\\xd8\\xac \\xd8\\xb9\\xd8\\xa7\\xd9\\x84\\xd8\\xac\\xd8\\xb2\\xd9\\x8a\\xd8\\xb1\\xd8\\xa9'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fW9eNYoGagID",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def lav_msa_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate Levantine to MSA: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDoUsP1AagIG",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"lav_msa_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"lav_msa_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=lav_msa_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[lav_msa_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path= filepath, #str(multibpemb.model_file), #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    #num_input_examples=num_nq_examples\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wIK8EWyaLFR",
        "colab_type": "text"
      },
      "source": [
        "###Maghrib to MSA Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bVhYmQnQaj2K",
        "colab": {}
      },
      "source": [
        "mag_msa_split_csv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"train/train_mag_msa.csv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"val/val_mag_msa.csv\")\n",
        "}\n",
        "mag_msa_example_count = {\n",
        "    \"train\": 14188,\n",
        "    \"validation\": 3548\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bb788e58-15e9-4375-e868-97fac32b2a11",
        "id": "WBLF-J2Oaj2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "def mag_msa_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(mag_msa_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(mag_msa_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)\n",
        "    print(example['source'].decode())\n",
        "    print(example['target'].decode())\n",
        "    print(len(example['source']))\n",
        "    print(len(example['target']))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b' \\xd8\\xa7\\xd9\\x86\\xd9\\x87\\xd8\\xa7 \\xd9\\x85\\xd8\\xb9\\xd9\\x84\\xd9\\x85\\xd8\\xa9 \\xd9\\x88\\xd8\\xa7\\xd8\\xa6\\xd9\\x84 \\xd8\\xaa\\xd8\\xaf\\xd8\\xb1\\xd8\\xb3\\xd9\\x87 \\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x84\\xd9\\x88\\xd9\\x85    ', 'target': b'\\xd9\\x87\\xd9\\x8a \\xd9\\x85\\xd8\\xb9\\xd9\\x84\\xd9\\x85\\xd8\\xa9 \\xd8\\xaf\\xd9\\x8a\\xd8\\xa7\\xd9\\x84 \\xd9\\x88\\xd8\\xa7\\xd8\\xa6\\xd9\\x84 \\xd9\\x83\\xd8\\xaa\\xd9\\x82\\xd8\\xb1\\xd9\\x8a\\xd9\\x87 \\xd8\\xb3\\xd9\\x8a\\xd8\\xa7\\xd9\\x86\\xd8\\xb3'}\n",
            " انها معلمة وائل تدرسه العلوم    \n",
            "هي معلمة ديال وائل كتقريه سيانس\n",
            "57\n",
            "57\n",
            "{'source': b' \\xd9\\x83\\xd8\\xa7\\xd9\\x86\\xd8\\xaa \\xd8\\xaa\\xd9\\x88\\xd8\\xac\\xd8\\xaf \\xd8\\xb4\\xd8\\xac\\xd8\\xb1\\xd8\\xa9 \\xd8\\xaa\\xd9\\x8a\\xd9\\x86 \\xd8\\xaa\\xd8\\xb9\\xd8\\xb7\\xd8\\xb1 \\xd9\\x83\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd8\\xad\\xd9\\x8a   ', 'target': b'\\xd9\\x83\\xd8\\xa7\\xd9\\x86\\xd8\\xaa \\xd9\\x88\\xd8\\xa7\\xd8\\xad\\xd8\\xaf \\xd8\\xb4\\xd8\\xac\\xd8\\xb1\\xd8\\xa9 \\xd8\\xa7\\xd9\\x84\\xd9\\x83\\xd8\\xb1\\xd9\\x85\\xd9\\x88\\xd8\\xb5 \\xd9\\x83\\xd8\\xaa\\xd8\\xb9\\xd8\\xb7\\xd8\\xb1 \\xd8\\xa7\\xd9\\x84\\xd8\\xad\\xd9\\x88\\xd9\\x85\\xd8\\xa9 \\xd9\\x83\\xd8\\xa7\\xd9\\x85\\xd9\\x84\\xd8\\xa9'}\n",
            " كانت توجد شجرة تين تعطر كل الحي   \n",
            "كانت واحد شجرة الكرموص كتعطر الحومة كاملة\n",
            "60\n",
            "76\n",
            "{'source': b'\\xd9\\x84\\xd8\\xa7  \\xd9\\x84\\xd9\\x82\\xd8\\xaf \\xd8\\xa7\\xd8\\xb9\\xd8\\xb7\\xd9\\x88\\xd8\\xa7 \\xd8\\xa7\\xd9\\x84\\xd8\\xb3\\xd9\\x84\\xd8\\xa7\\xd8\\xad \\xd9\\x83\\xd8\\xb1\\xd9\\x8a\\xd9\\x85\\xd8\\xa9', 'target': b'\\xd9\\x84\\xd8\\xa7 \\xd8\\xb1\\xd8\\xa7\\xd9\\x87 \\xd8\\xb9\\xd8\\xb7\\xd8\\xa7\\xd9\\x88 \\xd8\\xa7\\xd9\\x84\\xd8\\xb3\\xd9\\x84\\xd8\\xa7\\xd8\\xad \\xd9\\x83\\xd8\\xb1\\xd9\\x8a\\xd9\\x85\\xd8\\xa9'}\n",
            "لا  لقد اعطوا السلاح كريمة\n",
            "لا راه عطاو السلاح كريمة\n",
            "47\n",
            "44\n",
            "{'source': b' \\xd9\\x84\\xd9\\x86 \\xd8\\xa7\\xd9\\x82\\xd8\\xa8\\xd9\\x84 \\xd9\\x87\\xd9\\x86\\xd8\\xa7 \\xd8\\xaa\\xd8\\xb1\\xd8\\xaa\\xd9\\x8a\\xd8\\xa8\\xd9\\x8a \\xd8\\xba\\xd9\\x8a\\xd8\\xb1 \\xd8\\xac\\xd9\\x8a\\xd8\\xaf   ', 'target': b' \\xd9\\x87\\xd9\\x86\\xd8\\xa7 \\xd9\\x85\\xd8\\xa7 \\xd9\\x8a\\xd9\\x82\\xd8\\xa8\\xd9\\x84\\xd9\\x88\\xd9\\x86\\xd9\\x8a\\xd8\\xb4 \\xd9\\x84\\xd9\\x83\\xd9\\x84\\xd8\\xa7\\xd8\\xb3\\xd9\\x85\\xd9\\x88\\xd9\\x86 \\xd9\\x85\\xd8\\xaa\\xd8\\xa7\\xd8\\xb9\\xd9\\x8a \\xd9\\x85\\xd9\\x88\\xd8\\xb4 \\xd8\\xa8\\xd8\\xa7\\xd9\\x87\\xd9\\x8a'}\n",
            " لن اقبل هنا ترتيبي غير جيد   \n",
            " هنا ما يقبلونيش لكلاسمون متاعي موش باهي\n",
            "51\n",
            "73\n",
            "{'source': b'\\xd9\\x85\\xd8\\xa7 \\xd8\\xa7\\xd8\\xb3\\xd9\\x85\\xd9\\x87\\xd8\\xa7\\xd8\\x9f', 'target': b'\\xd8\\xb4\\xd9\\x86\\xd9\\x88 \\xd8\\xb3\\xd9\\x85\\xd9\\x8a\\xd8\\xaa\\xd9\\x87\\xd8\\xa7'}\n",
            "ما اسمها؟\n",
            "شنو سميتها\n",
            "17\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GgyqkGfYaj2Y",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def mag_msa_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate Maghrib to Arabic: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bmja1M2Eaj2f",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"mag_msa_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"mag_msa_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=mag_msa_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[mag_msa_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path= filepath, #str(multibpemb.model_file), #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    #num_input_examples=num_nq_examples\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLoe7vbFV42o",
        "colab_type": "text"
      },
      "source": [
        "##Dataset Mixture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMTtMsXWAua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.MixtureRegistry.remove(\"ar_translation\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"ar_translation\",\n",
        "    [\"msa_en_translation\", \"lav_msa_translation\", \"mag_msa_translation\"],\n",
        "     default_rate=1.0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc0bSgP1WenA",
        "colab_type": "text"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M23Y4l0tb4qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_SIZE = \"base\" #@param[\"small\", \"base\", \"large\"]\n",
        "# Public GCS path for T5 pre-trained model checkpoints\n",
        "BASE_PRETRAINED_DIR = \"gs://t5-data/pretrained_models\"\n",
        "PRETRAINED_DIR = os.path.join(BASE_PRETRAINED_DIR, MODEL_SIZE)\n",
        "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_SIZE)\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "# The models from our paper are based on the Mesh Tensorflow Transformer.\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 128},\n",
        "    learning_rate_schedule=0.003,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUCI7iq_WiFE",
        "colab_type": "code",
        "outputId": "5aa0eec7-5c71-4e05-f6d2-9cf6aacf4641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEPS = 1000000 #@param {type: \"integer\"}\n",
        "MODEL_SIZE = \"base\"\n",
        "model.train(\n",
        "    mixture_or_task_name=\"ar_translation\",\n",
        "    steps=STEPS,\n",
        "    )\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://t5at/models/base', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.49.75.2:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.49.75.2:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.49.75.2:8470', '_evaluation_master': 'grpc://10.49.75.2:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fdc6d68c5c0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.49.75.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.49.75.2:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4450726143852704177)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11895164336584338960)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2120144708214098891)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15461970980266009803)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6325990485774949180)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18114240340888726340)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16503393473106124817)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 882445562587749019)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17555894849780109499)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12042205970213719524)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7438039774368895251)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:enable_2d_tiling: False\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0]\n",
            "  [0 0 1]\n",
            "  [1 0 0]\n",
            "  [1 0 1]\n",
            "  [0 1 0]\n",
            "  [0 1 1]\n",
            "  [1 1 0]\n",
            "  [1 1 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0]]\n",
            "\n",
            " [[0 0 1]]\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " [[0 1 1]]\n",
            "\n",
            " [[1 0 0]]\n",
            "\n",
            " [[1 0 1]]\n",
            "\n",
            " [[1 1 0]]\n",
            "\n",
            " [[1 1 1]]]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=4, model=2] LayoutRules{('vocab', 'model'), ('d_ff', 'model'), ('ensemble', 'ensemble'), ('batch', 'batch'), ('experts', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fdcad95e320>\n",
            "INFO:tensorflow:serialize_num_microbatches: tokens_per_microbatch_per_replica=8192 batch_dim=Dimension(name='batch', size=128) sequence_length={'inputs': 128, 'targets': 128} batch_per_replica=32 num_microbatches=1\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 768147456    slice_size 384073728    Shape[vocab=1000192, d_model=768]                           \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 768          slice_size 384          Shape[stacked=2, heads=12, buckets=32]                      \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 47616        slice_size 47616        Shape[stacked=62, d_model=768]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 195     Total size: 966376704        Total slice_size: 483212160      \n",
            "INFO:tensorflow:All Variables                  count: 203     Total size: 967831552        Total slice_size: 484037504      \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 1.31e+05\n",
            " allconcat/0: 1.31e+05\n",
            "  allconcat/0/reshape_op: 1.31e+05\n",
            "allreduce: 7.01e+09\n",
            " allreduce/[0]: 3.88e+09\n",
            "  allreduce/[0]/einsum_op: 3.87e+09\n",
            "  allreduce/[0]/reduce_op: 1.89e+07\n",
            " allreduce/[1]: 3.12e+09\n",
            "  allreduce/[1]/einsum_op: 3.12e+09\n",
            "  allreduce/[1]/reduce_op: 1.32e+06\n",
            "einsum: 1.23e+14\n",
            "einsum_unique: 1.23e+14\n",
            "output: 4.02e+11\n",
            " output/AddOperation: 6.6e+10\n",
            " output/BinaryOpWithBroadcasting: 1.39e+09\n",
            " output/BroadcastOperation: 3.52e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 1.75e+11\n",
            " output/ImportOperation: 7.92e+05\n",
            " output/MinMaxOperation: 4.72e+06\n",
            " output/OneHotOperation: 4.93e+10\n",
            " output/RandomOperation: 2.91e+07\n",
            " output/RangeOperation: 2.05e+03\n",
            " output/ReduceOperation: 8.11e+08\n",
            " output/ReshapeOperation: 4.88e+09\n",
            " output/ScalarAddOperation: 3.87e+09\n",
            " output/ScalarMultiplyOperation: 1.83e+09\n",
            " output/ShiftOperation: 3.28e+04\n",
            " output/SlicewiseOperation: 4.19e+10\n",
            " output/StackOperation: 2.99e+06\n",
            " output/StackedVariable: 2.99e+06\n",
            " output/StopGradient: 1.73e+10\n",
            " output/UnstackOperation: 2.99e+06\n",
            " output/Variable: 3.87e+09\n",
            "output_unique: 3.41e+11\n",
            " output_unique/AddOperation: 5.81e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 1.31e+09\n",
            " output_unique/BroadcastOperation: 3.45e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 1.47e+11\n",
            " output_unique/ImportOperation: 9.9e+04\n",
            " output_unique/MinMaxOperation: 5.9e+05\n",
            " output_unique/OneHotOperation: 4.92e+10\n",
            " output_unique/RandomOperation: 2.28e+07\n",
            " output_unique/RangeOperation: 256\n",
            " output_unique/ReduceOperation: 7.15e+08\n",
            " output_unique/ReshapeOperation: 4.25e+09\n",
            " output_unique/ScalarAddOperation: 9.68e+08\n",
            " output_unique/ScalarMultiplyOperation: 9.13e+08\n",
            " output_unique/ShiftOperation: 1.64e+04\n",
            " output_unique/SlicewiseOperation: 2.64e+10\n",
            " output_unique/StackOperation: 5.03e+05\n",
            " output_unique/StackedVariable: 5.03e+05\n",
            " output_unique/StopGradient: 1.73e+10\n",
            " output_unique/UnstackOperation: 5.03e+05\n",
            " output_unique/Variable: 9.67e+08\n",
            "variables: 9.68e+08\n",
            " variables/trainable: 9.66e+08\n",
            " variables/untrainable: 1.45e+06\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Initialized dataset iterators in 11 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://t5at/models/base/model.ckpt.\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1352\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: From /job:worker/replica:0/task:0:\nBad hardware status: Queue is closed.\n\t [[{{node OutfeedDequeueTuple_6}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-0c5ab0fbdc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model.train(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ar_translation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/t5/models/mtf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mixture_or_task_name, steps, init_checkpoint, split)\u001b[0m\n\u001b[1;32m    235\u001b[0m     utils.train_model(self.estimator(vocabulary, init_checkpoint), vocabulary,\n\u001b[1;32m    236\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                       steps, self._ensemble_inputs, dataset_split=split)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   def eval(self, mixture_or_task_name, checkpoint_steps=None, summary_dir=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mesh_tensorflow/transformer/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(estimator, vocabulary, sequence_length, batch_size, train_dataset_fn, train_steps, ensemble_inputs, dataset_split)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m   \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_assertNotRegex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0mexec_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mcatch_errors\u001b[0;34m(self, source, session)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;34m\"\"\"Context manager to report any errors within a block.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_run_outfeed\u001b[0;34m(self, queue_ctx, session)\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outfeed dequeue for iteration (%d, %d)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mstep_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outfeed_every_n_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dequeue_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m           \u001b[0mstep_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m           \u001b[0mstatus_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outfeed finished for iteration (%d, %d)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 960\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1183\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1361\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1386\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: From /job:worker/replica:0/task:0:\nBad hardware status: Queue is closed.\n\t [[node OutfeedDequeueTuple_6 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:2179) ]]\n\nOriginal stack trace for 'OutfeedDequeueTuple_6':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-87-0c5ab0fbdc5f>\", line 5, in <module>\n    steps=STEPS,\n  File \"/usr/local/lib/python3.6/dist-packages/t5/models/mtf_model.py\", line 237, in train\n    steps, self._ensemble_inputs, dataset_split=split)\n  File \"/usr/local/lib/python3.6/dist-packages/mesh_tensorflow/transformer/utils.py\", line 1132, in train_model\n    estimator.train(input_fn=input_fn, max_steps=train_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n    saving_listeners=saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1194, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2857, in _call_model_fn\n    config)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1152, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3186, in _model_fn\n    host_ops = host_call.create_tpu_hostcall()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2179, in create_tpu_hostcall\n    device_ordinal=ordinal_id)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_tpu_ops.py\", line 2992, in outfeed_dequeue_tuple\n    device_ordinal=device_ordinal, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev_E4ZadXxmj",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjZnTOIrYEh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "051ba34e-6977-43c6-be27-27f054d5d7d6"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = train_batch_size * 4\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"ar_translation\",\n",
        "    checkpoint_steps=\"all\"\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://t5at/models/base', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.49.75.2:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.49.75.2:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.49.75.2:8470', '_evaluation_master': 'grpc://10.49.75.2:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fdc732c5978>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Checkpoint path gs://t5at/models/base/model.ckpt-999900\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.49.75.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.49.75.2:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4450726143852704177)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11895164336584338960)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2120144708214098891)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15461970980266009803)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6325990485774949180)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18114240340888726340)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16503393473106124817)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 882445562587749019)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17555894849780109499)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12042205970213719524)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7438039774368895251)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:enable_2d_tiling: False\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0]\n",
            "  [0 0 1]\n",
            "  [1 0 0]\n",
            "  [1 0 1]\n",
            "  [0 1 0]\n",
            "  [0 1 1]\n",
            "  [1 1 0]\n",
            "  [1 1 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0]]\n",
            "\n",
            " [[0 0 1]]\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " [[0 1 1]]\n",
            "\n",
            " [[1 0 0]]\n",
            "\n",
            " [[1 0 1]]\n",
            "\n",
            " [[1 1 0]]\n",
            "\n",
            " [[1 1 1]]]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=4, model=2] LayoutRules{('vocab', 'model'), ('d_ff', 'model'), ('ensemble', 'ensemble'), ('batch', 'batch'), ('experts', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fdc7ee7a358>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 24674304     slice_size 12337152     Shape[vocab=32128, d_model=768]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 768          slice_size 384          Shape[stacked=2, heads=12, buckets=32]                      \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 47616        slice_size 47616        Shape[stacked=62, d_model=768]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 195     Total size: 222903552        Total slice_size: 111475584      \n",
            "INFO:tensorflow:All Variables                  count: 195     Total size: 222903552        Total slice_size: 111475584      \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 1.18e+06\n",
            " allconcat/0: 1.18e+06\n",
            "  allconcat/0/reshape_op: 1.18e+06\n",
            "allreduce: 6.27e+09\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            " allreduce/[1]: 6.27e+09\n",
            "  allreduce/[1]/einsum_op: 6.27e+09\n",
            "  allreduce/[1]/reduce_op: 2.05e+03\n",
            "einsum: 1.84e+13\n",
            "einsum_unique: 1.84e+13\n",
            "output: 9.95e+10\n",
            " output/AddOperation: 1.82e+10\n",
            " output/BinaryOpWithBroadcasting: 2.09e+08\n",
            " output/Constant: 1.21e+09\n",
            " output/EinsumOperation: 4.09e+10\n",
            " output/ImportOperation: 6.56e+05\n",
            " output/MinMaxOperation: 4.85e+06\n",
            " output/OneHotOperation: 4.31e+09\n",
            " output/RangeOperation: 2.05e+03\n",
            " output/ReduceOperation: 6.48e+07\n",
            " output/ReshapeOperation: 9.77e+09\n",
            " output/ScalarAddOperation: 1.44e+07\n",
            " output/ScalarMultiplyOperation: 3.24e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 1.88e+10\n",
            " output/StackedVariable: 3.84e+05\n",
            " output/StopGradient: 3.62e+09\n",
            " output/UnstackOperation: 3.84e+05\n",
            " output/Variable: 8.91e+08\n",
            " output/WhileLoopOperation: 1.21e+09\n",
            "output_unique: 8.02e+10\n",
            " output_unique/AddOperation: 1.51e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 1.02e+08\n",
            " output_unique/Constant: 1.21e+09\n",
            " output_unique/EinsumOperation: 3.02e+10\n",
            " output_unique/ImportOperation: 8.2e+04\n",
            " output_unique/MinMaxOperation: 6.55e+05\n",
            " output_unique/OneHotOperation: 4.22e+09\n",
            " output_unique/RangeOperation: 256\n",
            " output_unique/ReduceOperation: 6.07e+07\n",
            " output_unique/ReshapeOperation: 8.51e+09\n",
            " output_unique/ScalarAddOperation: 4.85e+06\n",
            " output_unique/ScalarMultiplyOperation: 1.57e+08\n",
            " output_unique/ShiftOperation: 6.55e+04\n",
            " output_unique/SlicewiseOperation: 1.55e+10\n",
            " output_unique/StackedVariable: 4.84e+04\n",
            " output_unique/StopGradient: 3.62e+09\n",
            " output_unique/UnstackOperation: 4.84e+04\n",
            " output_unique/Variable: 2.23e+08\n",
            " output_unique/WhileLoopOperation: 1.21e+09\n",
            "variables: 2.23e+08\n",
            " variables/trainable: 2.23e+08\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://t5at/models/base/model.ckpt-999900\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 1: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 2: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 4: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 8: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 16: Translate MSA to English:  ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 32: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 64: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 128: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:decoded 256: Translate MSA to English:  ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: Translate Levantine to MSA:  ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇ :  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: Translate Levantine to MSA:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇ :  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇  \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:eval/msa_en_translation/accuracy at step 999900: 0.000\n",
            "INFO:tensorflow:eval/lav_msa_translation/accuracy at step 999900: 0.000\n",
            "INFO:tensorflow:eval/mag_msa_translation/accuracy at step 999900: 0.000\n",
            "INFO:tensorflow:Checkpoint path gs://t5at/models/base/model.ckpt-1000900\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=4, model=2] LayoutRules{('vocab', 'model'), ('d_ff', 'model'), ('ensemble', 'ensemble'), ('batch', 'batch'), ('experts', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fdc7ee7a358>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 294912       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 294912       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 1179648      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 1179648      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 24674304     slice_size 12337152     Shape[vocab=32128, d_model=768]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 768          slice_size 384          Shape[stacked=2, heads=12, buckets=32]                      \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 47616        slice_size 47616        Shape[stacked=62, d_model=768]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 195     Total size: 222903552        Total slice_size: 111475584      \n",
            "INFO:tensorflow:All Variables                  count: 195     Total size: 222903552        Total slice_size: 111475584      \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 1.18e+06\n",
            " allconcat/0: 1.18e+06\n",
            "  allconcat/0/reshape_op: 1.18e+06\n",
            "allreduce: 6.27e+09\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            " allreduce/[1]: 6.27e+09\n",
            "  allreduce/[1]/einsum_op: 6.27e+09\n",
            "  allreduce/[1]/reduce_op: 2.05e+03\n",
            "einsum: 1.84e+13\n",
            "einsum_unique: 1.84e+13\n",
            "output: 9.95e+10\n",
            " output/AddOperation: 1.82e+10\n",
            " output/BinaryOpWithBroadcasting: 2.09e+08\n",
            " output/Constant: 1.21e+09\n",
            " output/EinsumOperation: 4.09e+10\n",
            " output/ImportOperation: 6.56e+05\n",
            " output/MinMaxOperation: 4.85e+06\n",
            " output/OneHotOperation: 4.31e+09\n",
            " output/RangeOperation: 2.05e+03\n",
            " output/ReduceOperation: 6.48e+07\n",
            " output/ReshapeOperation: 9.77e+09\n",
            " output/ScalarAddOperation: 1.44e+07\n",
            " output/ScalarMultiplyOperation: 3.24e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 1.88e+10\n",
            " output/StackedVariable: 3.84e+05\n",
            " output/StopGradient: 3.62e+09\n",
            " output/UnstackOperation: 3.84e+05\n",
            " output/Variable: 8.91e+08\n",
            " output/WhileLoopOperation: 1.21e+09\n",
            "output_unique: 8.02e+10\n",
            " output_unique/AddOperation: 1.51e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 1.02e+08\n",
            " output_unique/Constant: 1.21e+09\n",
            " output_unique/EinsumOperation: 3.02e+10\n",
            " output_unique/ImportOperation: 8.2e+04\n",
            " output_unique/MinMaxOperation: 6.55e+05\n",
            " output_unique/OneHotOperation: 4.22e+09\n",
            " output_unique/RangeOperation: 256\n",
            " output_unique/ReduceOperation: 6.07e+07\n",
            " output_unique/ReshapeOperation: 8.51e+09\n",
            " output_unique/ScalarAddOperation: 4.85e+06\n",
            " output_unique/ScalarMultiplyOperation: 1.57e+08\n",
            " output_unique/ShiftOperation: 6.55e+04\n",
            " output_unique/SlicewiseOperation: 1.55e+10\n",
            " output_unique/StackedVariable: 4.84e+04\n",
            " output_unique/StopGradient: 3.62e+09\n",
            " output_unique/UnstackOperation: 4.84e+04\n",
            " output_unique/Variable: 2.23e+08\n",
            " output_unique/WhileLoopOperation: 1.21e+09\n",
            "variables: 2.23e+08\n",
            " variables/trainable: 2.23e+08\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://t5at/models/base/model.ckpt-1000900\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm sure Tom will be able to help me\n",
            "INFO:tensorflow:decoded 1: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go there\n",
            "INFO:tensorflow:decoded 2: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go there\n",
            "INFO:tensorflow:decoded 4: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go there\n",
            "INFO:tensorflow:decoded 8: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm sure Tom will be able to help me\n",
            "INFO:tensorflow:decoded 16: Translate MSA to English:  ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go\n",
            "INFO:tensorflow:decoded 32: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not sure what to say\n",
            "INFO:tensorflow:decoded 64: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm sure Tom will be able to help\n",
            "INFO:tensorflow:decoded 128: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm sure Tom will be able to help me\n",
            "INFO:tensorflow:decoded 256: Translate MSA to English:  ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not hungry\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go there\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: Translate MSA to English:  ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            -> I'm not going to go there\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: Translate Levantine to MSA:  ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: Translate Levantine to MSA:  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:            ->  ⁇   ⁇   ⁇   ⁇   ⁇   ⁇ \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:eval/msa_en_translation/accuracy at step 1000900: 0.000\n",
            "INFO:tensorflow:eval/lav_msa_translation/accuracy at step 1000900: 0.000\n",
            "INFO:tensorflow:eval/mag_msa_translation/accuracy at step 1000900: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF-3_4u1X-5r",
        "colab_type": "text"
      },
      "source": [
        "##Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL5yLXs4YJw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "49ededa4-3312-4603-d821-36a80162a134"
      },
      "source": [
        "msa_en_1 = \"احبك\" #@param {type:\"string\"}\n",
        "msa_en_2 = \"ماذا تقولون\" #@param {type:\"string\"}\n",
        "msa_en_3 = \"انا في بيتي\" #@param {type:\"string\"}\n",
        "msa_en_4 = \"مرحبا\" #@param {type:\"string\"}\n",
        "\n",
        "questions = [msa_en_1, msa_en_2, msa_en_3, msa_en_4]\n",
        "\n",
        "now = time.time()\n",
        "# Write out the supplied questions to text files.\n",
        "predict_inputs_path = os.path.join(MODEL_DIR, \"predict_inputs_%d.txt\" % now)\n",
        "predict_outputs_path = os.path.join(MODEL_DIR, \"predict_outputs_%d.txt\" % now)\n",
        "# Manually apply preprocessing by prepending \"triviaqa question:\".\n",
        "with tf.io.gfile.GFile(predict_inputs_path, \"w\") as f:\n",
        "  for q in questions:\n",
        "    f.write(\"Translate MSA to English: %s\\n\" % q.lower())\n",
        "\n",
        "# Ignore any logging so that we only see the model's answers to the questions.\n",
        "with tf_verbosity_level('ERROR'):\n",
        "  model.batch_size = 8  # Min size for small model on v2-8 with parallelism 1.\n",
        "  model.predict(\n",
        "      input_file=predict_inputs_path,\n",
        "      output_file=predict_outputs_path,\n",
        "      # Select the most probable output token at each step.\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "# The output filename will have the checkpoint appended so we glob to get \n",
        "# the latest.\n",
        "prediction_files = sorted(tf.io.gfile.glob(predict_outputs_path + \"*\"))\n",
        "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
        "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
        "  for q, a in zip(questions, f):\n",
        "    if q:\n",
        "      print(\"Q: \" + q)\n",
        "      print(\"A: \" + a)\n",
        "      print()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions using checkpoint 1000900:\n",
            "\n",
            "Q: احبك\n",
            "A: I'm going\n",
            "\n",
            "\n",
            "Q: ماذا تقولون\n",
            "A: I'm not hungry\n",
            "\n",
            "\n",
            "Q: انا في بيتي\n",
            "A: I'm not going to go\n",
            "\n",
            "\n",
            "Q: مرحبا\n",
            "A: I'm going\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}