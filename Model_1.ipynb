{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_1.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cba37d0eaf7b477fb3ae31639892334d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02b2a03df5f34193a0f898ee439e1998",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_168d6a31e28340b592627f7003f6aef8",
              "IPY_MODEL_f73bbc88e81c44ca8361bcc031fc5180"
            ]
          }
        },
        "02b2a03df5f34193a0f898ee439e1998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "168d6a31e28340b592627f7003f6aef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2bdb040fbad42bdbf657da77b620189",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6886f4b4b074409e9ec1468221355e85"
          }
        },
        "f73bbc88e81c44ca8361bcc031fc5180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_021be06d43b64a58b8170974a64d3dc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 44.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a44c7ed3dfd46feaf4d32f00a20013e"
          }
        },
        "e2bdb040fbad42bdbf657da77b620189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6886f4b4b074409e9ec1468221355e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "021be06d43b64a58b8170974a64d3dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a44c7ed3dfd46feaf4d32f00a20013e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93fca8325042411886f249f49f7cb550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc1d12eb91a642949d0c5b624adf9029",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c48fe50578a14104b6a32141c9b9dda3",
              "IPY_MODEL_a1160dc7d1b743289b33b977f4e1cc0b"
            ]
          }
        },
        "bc1d12eb91a642949d0c5b624adf9029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c48fe50578a14104b6a32141c9b9dda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea8eb069c7a54eccbaccc2b2270200ea",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab558f8a8fed464ca7f3c6e1aef72e1c"
          }
        },
        "a1160dc7d1b743289b33b977f4e1cc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa47591c8adc40148b945fa959fa95e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:17&lt;00:00, 50.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0d6273386054b02ad52984614f5dbb8"
          }
        },
        "ea8eb069c7a54eccbaccc2b2270200ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab558f8a8fed464ca7f3c6e1aef72e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa47591c8adc40148b945fa959fa95e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0d6273386054b02ad52984614f5dbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BQflUKhjIKNp"
      },
      "source": [
        "### Notes \n",
        "\n",
        "T5 Paper: https://arxiv.org/pdf/1910.10683.pdf\n",
        "\n",
        "T5 Tokenizer: https://github.com/huggingface/transformers/blob/master/src/transformers/tokenization_t5.py\n",
        "\n",
        "Important Tasks: https://docs.google.com/document/d/1weIZM6QTlnitpPQmpg-WeV2RW70TnYmDuogBQPr5mB0/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOmiOta6MJp",
        "colab_type": "code",
        "outputId": "f777e9f2-8f90-4e1e-b5c8-72feb38ef495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#installation step\n",
        "!pip install transformers\n",
        "!pip install t5\n",
        "!pip install sentencepiece\n",
        "!pip install bpemb\n",
        "#creating the folders \n",
        "!mkdir data/\n",
        "!mkdir data/AD_NMT-master\n",
        "!mkdir data/train/\n",
        "!mkdir data/test/\n",
        "!mkdir data/val/\n",
        "#fetching the pkl files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW' -O data/AD_NMT-master/english-Arabic-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1' -O data/AD_NMT-master/english-Arabic-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e' -O data/AD_NMT-master/english-Arabic-train.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV' -O data/AD_NMT-master/LAV-MSA-2-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3' -O data/AD_NMT-master/LAV-MSA-2-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw' -O data/AD_NMT-master/LAV-MSA-2-train.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16' -O data/AD_NMT-master/Magribi_MSA-both.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l' -O data/AD_NMT-master/Magribi_MSA-test.pkl\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ' -O data/AD_NMT-master/Magribi_MSA-train.pkl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 3.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 60.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=060bf2b2c0bcd454436a9a1af42d012db63f441c8b6b1723b2b4466d50757f1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.9.0\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/93/e25d0043ece218a94d14f710c553bbcc7974d2ff169b4aa8f8d1423dca95/t5-0.5.0-py3-none-any.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.4MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5) (1.4.1)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/32/ceaf1549586ccfeaf7840a166876be358bd78ab2fdd152b17c5600ed7888/mesh_tensorflow-0.1.13-py3-none-any.whl (292kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5) (0.3.0)\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/42/df5f05f2124f9d1b6e16b88c518f04a7d282d77daf3113ba548baadc4ce5/tfds_nightly-3.1.0.dev202005100106-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from t5) (0.1.86)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5) (2.8.0)\n",
            "Collecting six>=1.14\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5) (0.22.2.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5) (1.5.0+cu101)\n",
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/35/b87b84648f84b9021df3407422d3cf9afdcbb9b087d2bf293fe72557b7a5/tensorflow_text-2.1.1-cp36-cp36m-manylinux1_x86_64.whl (8.3MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5) (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5) (1.18.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5) (1.0.3)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from t5) (2.9.0)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->t5) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets; extra == \"transformer\" in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (2.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (0.3.1.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (3.10.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (1.1.0)\n",
            "Collecting tensorflow-metadata<0.16,>=0.15\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/0c/afb81ea6998f6e26521671585d1cd9d3f7945a8b9834764e91757453dc25/tensorflow_metadata-0.15.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (19.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (4.41.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5) (1.12.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5) (0.14.1)\n",
            "Collecting tensorflow<2.2,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->t5) (2.8.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly->t5) (46.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata<0.16,>=0.15->tfds-nightly->t5) (1.51.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly->t5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly->t5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly->t5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly->t5) (3.0.4)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.28.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5) (7.1.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (2.10.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1.0->tensorflow-text->t5) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=90cec053833d4b6f7da4bebb3069a2fd871f5b6713511dbf2af2837fbc0d8f2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: portalocker, sacrebleu, six, mesh-tensorflow, tensorflow-metadata, tfds-nightly, tensorboard, gast, tensorflow-estimator, tensorflow, tensorflow-text, rouge-score, t5\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: tensorflow-metadata 0.21.2\n",
            "    Uninstalling tensorflow-metadata-0.21.2:\n",
            "      Successfully uninstalled tensorflow-metadata-0.21.2\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed gast-0.2.2 mesh-tensorflow-0.1.13 portalocker-1.7.0 rouge-score-0.0.3 sacrebleu-1.4.9 six-1.14.0 t5-0.5.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tensorflow-metadata-0.15.2 tensorflow-text-2.1.1 tfds-nightly-3.1.0.dev202005100106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.86)\n",
            "Collecting bpemb\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bpemb) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb) (0.1.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb) (1.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (1.13.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (1.16.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim->bpemb) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.2.1->gensim->bpemb) (2.8.1)\n",
            "Installing collected packages: bpemb\n",
            "Successfully installed bpemb-0.3.0\n",
            "--2020-05-10 12:36:16--  https://docs.google.com/uc?export=download&id=1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.113, 108.177.111.138, 108.177.111.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rnfd7kve005o778imai44aq5lbqhn7qn/1589114175000/16970776037313924126/*/1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:17--  https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rnfd7kve005o778imai44aq5lbqhn7qn/1589114175000/16970776037313924126/*/1V9crCmqvgQcv0Sx2MCNWB9AET2j6M6FW?e=download\n",
            "Resolving doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 955428 (933K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 933.04K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2020-05-10 12:36:17 (154 MB/s) - ‘data/AD_NMT-master/english-Arabic-both.pkl’ saved [955428/955428]\n",
            "\n",
            "--2020-05-10 12:36:18--  https://docs.google.com/uc?export=download&id=1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.138, 108.177.111.101, 108.177.111.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q7ia0elolih3g9gnq4utk3a9khskj2uk/1589114175000/16970776037313924126/*/1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:18--  https://doc-14-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q7ia0elolih3g9gnq4utk3a9khskj2uk/1589114175000/16970776037313924126/*/1V8_tp8ZlWUYaX7QQL46t0uSRNrVehSf1?e=download\n",
            "Resolving doc-14-2s-docs.googleusercontent.com (doc-14-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-14-2s-docs.googleusercontent.com (doc-14-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95497 (93K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>]  93.26K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-05-10 12:36:19 (146 MB/s) - ‘data/AD_NMT-master/english-Arabic-test.pkl’ saved [95497/95497]\n",
            "\n",
            "--2020-05-10 12:36:19--  https://docs.google.com/uc?export=download&id=1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.100, 108.177.111.102, 108.177.111.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nb914052vftn5g7uqvsk8eu4ripr01ai/1589114175000/16970776037313924126/*/1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:20--  https://doc-10-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nb914052vftn5g7uqvsk8eu4ripr01ai/1589114175000/16970776037313924126/*/1V7X0qtuDIyjTHY0wh-ZNoVwsiF4lId2e?e=download\n",
            "Resolving doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-10-2s-docs.googleusercontent.com (doc-10-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 859172 (839K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/english-Arabic-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 839.04K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2020-05-10 12:36:20 (140 MB/s) - ‘data/AD_NMT-master/english-Arabic-train.pkl’ saved [859172/859172]\n",
            "\n",
            "--2020-05-10 12:36:21--  https://docs.google.com/uc?export=download&id=1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.100, 108.177.111.139, 108.177.111.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nhrgbiib3ongf7sb1ehv65494kahvkv5/1589114175000/16970776037313924126/*/1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:22--  https://doc-00-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nhrgbiib3ongf7sb1ehv65494kahvkv5/1589114175000/16970776037313924126/*/1UzL4cOWTMCee83KBUh2QO_H62AFVpDQV?e=download\n",
            "Resolving doc-00-2s-docs.googleusercontent.com (doc-00-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-00-2s-docs.googleusercontent.com (doc-00-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.33M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-10 12:36:22 (122 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-both.pkl’ saved [2447014]\n",
            "\n",
            "--2020-05-10 12:36:23--  https://docs.google.com/uc?export=download&id=1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.101, 108.177.111.138, 108.177.111.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/u9c4g9r7fpbbmjqhelocdg5meeilnelt/1589114175000/16970776037313924126/*/1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:23--  https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/u9c4g9r7fpbbmjqhelocdg5meeilnelt/1589114175000/16970776037313924126/*/1UpfCbkxhztof7dvNjeAs1bHjD4SER6h3?e=download\n",
            "Resolving doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 304332 (297K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 297.20K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-05-10 12:36:24 (144 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-test.pkl’ saved [304332/304332]\n",
            "\n",
            "--2020-05-10 12:36:25--  https://docs.google.com/uc?export=download&id=1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.197.138, 173.194.197.139, 173.194.197.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.197.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mes4lphgp2n6f7le61i799o3gms2kdsa/1589114175000/16970776037313924126/*/1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:25--  https://doc-0c-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mes4lphgp2n6f7le61i799o3gms2kdsa/1589114175000/16970776037313924126/*/1UlAZGtYsSfXzK7hrC_PbxQFqTSXD0DMw?e=download\n",
            "Resolving doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0c-2s-docs.googleusercontent.com (doc-0c-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/LAV-MSA-2-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.04M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-05-10 12:36:25 (197 MB/s) - ‘data/AD_NMT-master/LAV-MSA-2-train.pkl’ saved [2141923]\n",
            "\n",
            "--2020-05-10 12:36:26--  https://docs.google.com/uc?export=download&id=1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.139, 108.177.111.101, 108.177.111.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/l3t9b0i4b8pe38rvg40pqr2inqe681s1/1589114175000/16970776037313924126/*/1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:27--  https://doc-04-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/l3t9b0i4b8pe38rvg40pqr2inqe681s1/1589114175000/16970776037313924126/*/1UjDX7cCG2S23SPfSHxSPdVayMTxB5Y16?e=download\n",
            "Resolving doc-04-2s-docs.googleusercontent.com (doc-04-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-04-2s-docs.googleusercontent.com (doc-04-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-both.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.81M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-05-10 12:36:28 (267 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-both.pkl’ saved [2944107]\n",
            "\n",
            "--2020-05-10 12:36:28--  https://docs.google.com/uc?export=download&id=1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.113, 108.177.111.100, 108.177.111.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kmah3gkq3i4vq1n2onll1iirtshf94ms/1589114175000/16970776037313924126/*/1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:29--  https://doc-0o-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kmah3gkq3i4vq1n2onll1iirtshf94ms/1589114175000/16970776037313924126/*/1UaVWIqRXo0rxuxDF4KArA4bEK1TaLX3l?e=download\n",
            "Resolving doc-0o-2s-docs.googleusercontent.com (doc-0o-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0o-2s-docs.googleusercontent.com (doc-0o-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290840 (284K) [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-test.pkl’\n",
            "\n",
            "data/AD_NMT-master/ 100%[===================>] 284.02K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-05-10 12:36:29 (145 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-test.pkl’ saved [290840/290840]\n",
            "\n",
            "--2020-05-10 12:36:30--  https://docs.google.com/uc?export=download&id=1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.101, 108.177.111.102, 108.177.111.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/54tf37ji9qk3hgrfn35b2jb5e726e3g0/1589114175000/16970776037313924126/*/1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-05-10 12:36:31--  https://doc-0s-2s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/54tf37ji9qk3hgrfn35b2jb5e726e3g0/1589114175000/16970776037313924126/*/1UYvlhdYAdfa4riP_4hn3-IEVd1ZUXVTQ?e=download\n",
            "Resolving doc-0s-2s-docs.googleusercontent.com (doc-0s-2s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0s-2s-docs.googleusercontent.com (doc-0s-2s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/AD_NMT-master/Magribi_MSA-train.pkl’\n",
            "\n",
            "data/AD_NMT-master/     [ <=>                ]   2.53M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-05-10 12:36:31 (247 MB/s) - ‘data/AD_NMT-master/Magribi_MSA-train.pkl’ saved [2652508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-WzhRv4mIKNq",
        "colab": {}
      },
      "source": [
        "#James Chartouni\n",
        "#Joey Park\n",
        "#Raef Khan\n",
        "\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os, io, glob\n",
        "import functools\n",
        "\n",
        "import sentencepiece as spm\n",
        "from bpemb import BPEmb\n",
        "\n",
        "import transformers\n",
        "import t5\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxCLgMZ2ns4b",
        "colab_type": "text"
      },
      "source": [
        "##Initial Loading from Pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T67vZ0Nv4-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aha0xureIKNw",
        "outputId": "ef644170-ec21-41cb-85c4-dcdf43ecfefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls data/AD_NMT-master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english-Arabic-both.pkl   LAV-MSA-2-both.pkl   Magribi_MSA-both.pkl\n",
            "english-Arabic-test.pkl   LAV-MSA-2-test.pkl   Magribi_MSA-test.pkl\n",
            "english-Arabic-train.pkl  LAV-MSA-2-train.pkl  Magribi_MSA-train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWKnGRlLIKN9",
        "colab": {}
      },
      "source": [
        "file_path = 'data/AD_NMT-master/'\n",
        "\n",
        "with open(file_path + \"english-Arabic-train.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_trainval = pickle.load(handle)\n",
        "\n",
        "with open(file_path + \"english-Arabic-test.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_test = pickle.load(handle)\n",
        "\n",
        "with open(file_path + \"english-Arabic-both.pkl\", 'rb') as handle:\n",
        "    data_MSA_English_both = pickle.load(handle) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-train.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_trainval = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-test.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_test = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"LAV-MSA-2-both.pkl\", 'rb') as handle:\n",
        "    data_LAV_MSA_both = pickle.load(handle) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(file_path + \"Magribi_MSA-train.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_trainval = pickle.load(handle) \n",
        "    \n",
        "with open(file_path + \"Magribi_MSA-test.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_test = pickle.load(handle) \n",
        "\n",
        "with open(file_path + \"Magribi_MSA-both.pkl\", 'rb') as handle:\n",
        "    data_Magribi_MSA_both = pickle.load(handle) \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ch3APJadIKOH",
        "outputId": "0b83a118-21bf-4857-9056-827fdc24bf5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#few dataset examples\n",
        "print(data_MSA_English_both[0:5])\n",
        "print(data_LAV_MSA_both[0:5])\n",
        "\n",
        "#print length of train + val dataset, print length of both (train + val) + test\n",
        "print(len(data_MSA_English_trainval))\n",
        "print(len(data_MSA_English_both))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Tom was also there', 'كان توم هنا ايضا'], ['That old woman lives by herself', 'تلك المراة العجوز تسكن بمفردها'], ['He went abroad for the purpose of studying English', 'سافر خارج البلد ليتعلم الانجليزية'], ['There is a fork missing', 'هناك شوكة ناقصة'], [\"I don't know this game\", 'لا اعرف هذه اللعبة']]\n",
            "[['لا انا بعرف وحدة راحت ع فرنسا و معا شنتا حطت فيها الفرش', 'لا اعرف واحدة ذهبت الى فرنسا و لها غرفة و ضعت فيها الافرشة'], ['روح بوشك و فتول عاليسار', 'اذهب تقدم و استدر يسارا'], ['لا لا لازم انه يكون عندك موضوع ما في اشي', ' لا لا يجب ان يكون لديك موضوع هذا ضروري'], ['اوعي تبعدي من هون بلاش تضيعي ', 'لا تبتعد عن هنا حتى لا تفقد الطريق '], ['قصدي صراحة يما انا كمان كرهته من يوم ما عملتيه زي ما بتعمله خالتي كرهته و صرت ما باطيقه بالمرة', 'اقصد صراحة يا امي انا ايضا كرهته من يوم حضرته مثلما تحضره خالتي كرهته و اصبحت لا اطيقه ابدا']]\n",
            "9000\n",
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "irQQ9E_7IKOM"
      },
      "source": [
        "## Prepare Datasets\n",
        "\n",
        "example: https://iwslt2010.fbk.eu/node/32/\n",
        "\n",
        "We need to take our training and test sets from the pkl files and create new .txt files that are formatted so that the standard torchtext Dataset class can read them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "raw",
        "id": "ikpu9B5dIKON"
      },
      "source": [
        "Data format:\n",
        "each line consists of three fields divided by the character '\\'\n",
        "sentences consisting of words divided by single spaces\n",
        "format: <SENTENCE_ID>\\<PARAPHRASE_ID>\\<TEXT>\n",
        "Field_1: sentence ID\n",
        "Field_2: paraphrase ID\n",
        "Field_3: MT develop sentence / reference translation\n",
        "Text input example:\n",
        "DEV_001\\01\\This is the first develop sentence.\n",
        "DEV_002\\01\\This is the second develop sentence.\n",
        "Reference translation example:\n",
        "DEV_001\\01\\1st reference translation for 1st input\n",
        "DEV_001\\02\\2nd reference translation for 1st input\n",
        "...\n",
        "DEV_002\\01\\1st reference translation for 2nd input\n",
        "DEV_002\\02\\2nd reference translation for 2nd input\n",
        "...\n",
        "Languages:\n",
        "Arabic-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n",
        "IWSLT05 testset: 506 sentences, 16 reference translations\n",
        "IWSLT07 testset: 489 sentences, 6 reference translations\n",
        "IWSLT08 testset: 507 sentences, 16 reference translations\n",
        "French-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n",
        "IWSLT05 testset: 506 sentences, 16 reference translations\n",
        "Turkish-English\n",
        "CSTAR03 testset: 506 sentences, 16 reference translations\n",
        "IWSLT04 testset: 500 sentences, 16 reference translations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7wcnDJDKwqED",
        "outputId": "b17a66a5-2aca-4faf-c48e-2e4bd1ba4afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls data/AD_NMT-master/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english-Arabic-both.pkl   LAV-MSA-2-both.pkl   Magribi_MSA-both.pkl\n",
            "english-Arabic-test.pkl   LAV-MSA-2-test.pkl   Magribi_MSA-test.pkl\n",
            "english-Arabic-train.pkl  LAV-MSA-2-train.pkl  Magribi_MSA-train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lp7ncVY6wqET",
        "colab": {}
      },
      "source": [
        "#splits the train dataset into train and validation sets, define test set as datafile\n",
        "msa_en_train, msa_en_val = train_test_split(data_MSA_English_trainval, test_size=.2)\n",
        "msa_en_test = data_MSA_English_test\n",
        "\n",
        "lav_msa_train, lav_msa_val = train_test_split(data_LAV_MSA_trainval, test_size=.2)\n",
        "lav_msa_test = data_LAV_MSA_test\n",
        "\n",
        "mag_msa_train, mag_msa_val = train_test_split(data_Magribi_MSA_trainval, test_size=.2)\n",
        "mag_msa_test = data_Magribi_MSA_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Ue2fSILwqEW",
        "outputId": "023f4b4a-781a-47f4-b0e4-f68bea849f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(len(msa_en_train))\n",
        "print(len(msa_en_val))\n",
        "\n",
        "print(len(lav_msa_train))\n",
        "print(len(lav_msa_val))\n",
        "\n",
        "print(len(mag_msa_train))\n",
        "print(len(mag_msa_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7200\n",
            "1800\n",
            "11044\n",
            "2761\n",
            "14188\n",
            "3548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3bWU46TIKOb",
        "colab": {}
      },
      "source": [
        "file_path = 'data/'\n",
        "\n",
        "def list_to_csv(ds, src='msa', trg='en', datatype=''):\n",
        "    src_formatted = datatype + '_' + src + '_' + trg + '.' + 'csv'\n",
        "    \n",
        "    with open(file_path + datatype + \"/\" + src_formatted, 'wt') as csv:\n",
        "        for i, arr in enumerate(ds):\n",
        "            csv.write(arr[1] + ',' + arr[0] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AqwDB9BuKEnV",
        "colab": {}
      },
      "source": [
        "list_to_csv(msa_en_train, 'msa', 'en', 'train')\n",
        "list_to_csv(msa_en_val, 'msa', 'en', 'val')\n",
        "list_to_csv(msa_en_test, 'msa', 'en', 'test')\n",
        "\n",
        "list_to_csv(lav_msa_train, 'lav', 'msa', 'train')\n",
        "list_to_csv(lav_msa_val, 'lav', 'msa', 'val')\n",
        "list_to_csv(lav_msa_test, 'lav', 'msa', 'test')\n",
        "\n",
        "list_to_csv(mag_msa_train, 'mag', 'msa', 'train')\n",
        "list_to_csv(mag_msa_val, 'mag', 'msa', 'val')\n",
        "list_to_csv(mag_msa_test, 'mag', 'msa', 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19T4J6mOmKff",
        "colab_type": "text"
      },
      "source": [
        "##Loading MultiBPemb: Multilingual BPEmb Sentencepiece Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AgOklFxmWEr",
        "colab_type": "code",
        "outputId": "0ade993c-2467-46f2-ba7e-71911e40bbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "multibpemb = BPEmb(lang=\"multi\", vs=100000, dim=300)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/multi/multi.wiki.bpe.vs100000.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1965223/1965223 [00:00<00:00, 2021646.66B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/multi/multi.wiki.bpe.vs100000.d300.w2v.bin.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 112202964/112202964 [00:05<00:00, 19412663.57B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecOIDSp--C7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "836a6e8d-96d6-48be-b043-ec28ccab081f"
      },
      "source": [
        "print(multibpemb.EOS) #this might be an issue, as the SentencePieceVocabulary class in t5/data/sentencepiece_vocabulary.py assumes that ID=1 for EOS"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag6soPRLhcwY",
        "colab_type": "code",
        "outputId": "dbb8eb87-812d-4d8e-a4c2-ef2bd236d485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filepath = str(multibpemb.model_file)\n",
        "print(filepath)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.cache/bpemb/multi/multi.wiki.bpe.vs100000.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDLAC0m2uY8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "19ce394b-dd88-496b-d33b-0d9acfb3e465"
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 238, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/238)\u001b[K\rremote: Counting objects:   1% (3/238)\u001b[K\rremote: Counting objects:   2% (5/238)\u001b[K\rremote: Counting objects:   3% (8/238)\u001b[K\rremote: Counting objects:   4% (10/238)\u001b[K\rremote: Counting objects:   5% (12/238)\u001b[K\rremote: Counting objects:   6% (15/238)\u001b[K\rremote: Counting objects:   7% (17/238)\u001b[K\rremote: Counting objects:   8% (20/238)\u001b[K\rremote: Counting objects:   9% (22/238)\u001b[K\rremote: Counting objects:  10% (24/238)\u001b[K\rremote: Counting objects:  11% (27/238)\u001b[K\rremote: Counting objects:  12% (29/238)\u001b[K\rremote: Counting objects:  13% (31/238)\u001b[K\rremote: Counting objects:  14% (34/238)\u001b[K\rremote: Counting objects:  15% (36/238)\u001b[K\rremote: Counting objects:  16% (39/238)\u001b[K\rremote: Counting objects:  17% (41/238)\u001b[K\rremote: Counting objects:  18% (43/238)\u001b[K\rremote: Counting objects:  19% (46/238)\u001b[K\rremote: Counting objects:  20% (48/238)\u001b[K\rremote: Counting objects:  21% (50/238)\u001b[K\rremote: Counting objects:  22% (53/238)\u001b[K\rremote: Counting objects:  23% (55/238)\u001b[K\rremote: Counting objects:  24% (58/238)\u001b[K\rremote: Counting objects:  25% (60/238)\u001b[K\rremote: Counting objects:  26% (62/238)\u001b[K\rremote: Counting objects:  27% (65/238)\u001b[K\rremote: Counting objects:  28% (67/238)\u001b[K\rremote: Counting objects:  29% (70/238)\u001b[K\rremote: Counting objects:  30% (72/238)\u001b[K\rremote: Counting objects:  31% (74/238)\u001b[K\rremote: Counting objects:  32% (77/238)\u001b[K\rremote: Counting objects:  33% (79/238)\u001b[K\rremote: Counting objects:  34% (81/238)\u001b[K\rremote: Counting objects:  35% (84/238)\u001b[K\rremote: Counting objects:  36% (86/238)\u001b[K\rremote: Counting objects:  37% (89/238)\u001b[K\rremote: Counting objects:  38% (91/238)\u001b[K\rremote: Counting objects:  39% (93/238)\u001b[K\rremote: Counting objects:  40% (96/238)\u001b[K\rremote: Counting objects:  41% (98/238)\u001b[K\rremote: Counting objects:  42% (100/238)\rremote: Counting objects:  43% (103/238)\u001b[K\rremote: Counting objects:  44% (105/238)\u001b[K\rremote: Counting objects:  45% (108/238)\u001b[K\rremote: Counting objects:  46% (110/238)\u001b[K\rremote: Counting objects:  47% (112/238)\u001b[K\rremote: Counting objects:  48% (115/238)\u001b[K\rremote: Counting objects:  49% (117/238)\u001b[K\rremote: Counting objects:  50% (119/238)\u001b[K\rremote: Counting objects:  51% (122/238)\u001b[K\rremote: Counting objects:  52% (124/238)\u001b[K\rremote: Counting objects:  53% (127/238)\u001b[K\rremote: Counting objects:  54% (129/238)\u001b[K\rremote: Counting objects:  55% (131/238)\u001b[K\rremote: Counting objects:  56% (134/238)\u001b[K\rremote: Counting objects:  57% (136/238)\u001b[K\rremote: Counting objects:  58% (139/238)\u001b[K\rremote: Counting objects:  59% (141/238)\u001b[K\rremote: Counting objects:  60% (143/238)\u001b[K\rremote: Counting objects:  61% (146/238)\u001b[K\rremote: Counting objects:  62% (148/238)\u001b[K\rremote: Counting objects:  63% (150/238)\u001b[K\rremote: Counting objects:  64% (153/238)\u001b[K\rremote: Counting objects:  65% (155/238)\u001b[K\rremote: Counting objects:  66% (158/238)\u001b[K\rremote: Counting objects:  67% (160/238)\u001b[K\rremote: Counting objects:  68% (162/238)\u001b[K\rremote: Counting objects:  69% (165/238)\u001b[K\rremote: Counting objects:  70% (167/238)\u001b[K\rremote: Counting objects:  71% (169/238)\u001b[K\rremote: Counting objects:  72% (172/238)\u001b[K\rremote: Counting objects:  73% (174/238)\u001b[K\rremote: Counting objects:  74% (177/238)\u001b[K\rremote: Counting objects:  75% (179/238)\u001b[K\rremote: Counting objects:  76% (181/238)\u001b[K\rremote: Counting objects:  77% (184/238)\u001b[K\rremote: Counting objects:  78% (186/238)\u001b[K\rremote: Counting objects:  79% (189/238)\u001b[K\rremote: Counting objects:  80% (191/238)\u001b[K\rremote: Counting objects:  81% (193/238)\u001b[K\rremote: Counting objects:  82% (196/238)\u001b[K\rremote: Counting objects:  83% (198/238)\u001b[K\rremote: Counting objects:  84% (200/238)\u001b[K\rremote: Counting objects:  85% (203/238)\u001b[K\rremote: Counting objects:  86% (205/238)\u001b[K\rremote: Counting objects:  87% (208/238)\u001b[K\rremote: Counting objects:  88% (210/238)\u001b[K\rremote: Counting objects:  89% (212/238)\u001b[K\rremote: Counting objects:  90% (215/238)\u001b[K\rremote: Counting objects:  91% (217/238)\u001b[K\rremote: Counting objects:  92% (219/238)\u001b[K\rremote: Counting objects:  93% (222/238)\u001b[K\rremote: Counting objects:  94% (224/238)\u001b[K\rremote: Counting objects:  95% (227/238)\u001b[K\rremote: Counting objects:  96% (229/238)\u001b[K\rremote: Counting objects:  97% (231/238)\u001b[K\rremote: Counting objects:  98% (234/238)\u001b[K\rremote: Counting objects:  99% (236/238)\u001b[K\rremote: Counting objects: 100% (238/238)\u001b[K\rremote: Counting objects: 100% (238/238), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 2864 (delta 117), reused 115 (delta 59), pack-reused 2626\u001b[K\n",
            "Receiving objects: 100% (2864/2864), 28.33 MiB | 24.23 MiB/s, done.\n",
            "Resolving deltas: 100% (1890/1890), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo_nQJ96zZc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8efb5e1-b1c6-4545-d991-838c45c9fe9c"
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 1,818 kB of archives.\n",
            "After this operation, 7,685 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-pil amd64 5.1.0-1ubuntu0.2 [329 kB]\n",
            "Fetched 1,818 kB in 1s (1,807 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlMAL5LysKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f4fdf206-84b0-4a3b-e24e-e1eaab629ed8"
      },
      "source": [
        "!cd sentencepiece/src\n",
        "!protoc --python_out=. sentencepiece_model.proto\n",
        "! ls *.py"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: sentencepiece/src: No such file or directory\n",
            "sentencepiece_model_pb2.py\n",
            "/bin/bash: sentencepiece_model_pb2.py: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pb4wRIi2scA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f931c9b-8ea9-4332-d7e9-1e5f779a0e81"
      },
      "source": [
        "import sentencepiece_model_pb2 as model\n",
        "m = model.ModelProto()\n",
        "m.ParseFromString(open(filepath, 'rb').read())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1965223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgtoP-oq3Q3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.pieces[0].piece = \"<pad>\"\n",
        "m.pieces[0].type = 3\n",
        "m.pieces[1].piece = \"</s>\"\n",
        "m.pieces[1].type = 3\n",
        "m.pieces[2].piece = \"<unk>\"\n",
        "m.pieces[2].type = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnJXSLyP8hKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3ee6106e-99f2-4c14-d77e-1686736a56ea"
      },
      "source": [
        "print(m.pieces[0])\n",
        "print(m.pieces[1])\n",
        "print(m.pieces[2])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "piece: \"<pad>\"\n",
            "type: CONTROL\n",
            "\n",
            "piece: \"</s>\"\n",
            "type: CONTROL\n",
            "\n",
            "piece: \"<unk>\"\n",
            "type: UNKNOWN\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyt6b_-K9CdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('multibpemb.model', 'wb') as f:\n",
        "  f.write(m.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTMz1jJBlNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "git clone https://github.com/Microsoft/vcpkg.git\n",
        "cd vcpkg\n",
        "./bootstrap-vcpkg.sh\n",
        "./vcpkg integrate install\n",
        "./vcpkg install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AHAMQpFBs0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! spm_export_vocab --model=multibpemb.model --output_format=proto | less"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHAuzNW1eIh",
        "colab_type": "text"
      },
      "source": [
        "##Tensor Processing + Add to TaskRegistry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVVzdeAZd0x",
        "colab_type": "text"
      },
      "source": [
        "### MSA to English Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWnZcYI_491p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msa_en_split_csv_path = {\n",
        "    \"train\": \"data/train/train_msa_en.csv\",\n",
        "    \"validation\": \"data/val/val_msa_en.csv\"\n",
        "}\n",
        "msa_en_example_count = {\n",
        "    \"train\": 7200,\n",
        "    \"validation\": 1800\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2e3cM_wP_M8",
        "colab_type": "code",
        "outputId": "0da23dfb-f043-48b5-f16f-46ee1d0fb1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def msa_en_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(msa_en_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(msa_en_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b'\\xd9\\x84\\xd9\\x85 \\xd8\\xa7\\xd9\\x82\\xd8\\xa7\\xd8\\xa8\\xd9\\x84\\xd9\\x87 \\xd9\\x85\\xd9\\x86 \\xd9\\x82\\xd8\\xa8\\xd9\\x84', 'target': b\"I've never met him\"}\n",
            "{'source': b'\\xd9\\x84\\xd9\\x8a\\xd8\\xaa\\xd9\\x86\\xd9\\x8a \\xd9\\x83\\xd9\\x86\\xd8\\xaa \\xd8\\xa7\\xd8\\xb9\\xd8\\xb1\\xd9\\x81 \\xd8\\xa7\\xd9\\x8a\\xd9\\x86 \\xd9\\x87\\xd9\\x88!', 'target': b'I wish I knew where he was!'}\n",
            "{'source': b'\\xd8\\xac\\xd8\\xa7\\xd8\\xa1 \\xd9\\x84\\xd9\\x8a\\xd8\\xb7\\xd9\\x84\\xd8\\xa8 \\xd9\\x85\\xd9\\x86\\xd8\\xa7 \\xd8\\xa7\\xd9\\x86 \\xd9\\x86\\xd8\\xb3\\xd8\\xa7\\xd8\\xb9\\xd8\\xaf\\xd9\\x87', 'target': b'He came to ask us to help him'}\n",
            "{'source': b'\\xd9\\x82\\xd9\\x84\\xd8\\xaa \\xd9\\x84\\xd9\\x87 \\xd8\\xa7\\xd9\\x86 \\xd9\\x8a\\xd8\\xa7\\xd8\\xaa\\xd9\\x8a', 'target': b'I told him to come'}\n",
            "{'source': b'\\xd9\\x84\\xd9\\x85 \\xd9\\x8a\\xd9\\x83\\xd9\\x86 \\xd9\\x87\\xd8\\xb0\\xd8\\xa7 \\xd9\\x85\\xd8\\xa7 \\xd8\\xa7\\xd8\\xb1\\xd8\\xaf\\xd8\\xaa \\xd8\\xb3\\xd9\\x85\\xd8\\xa7\\xd8\\xb9\\xd9\\x87', 'target': b\"That wasn't what I wanted to hear\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1GXED2IO3pE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def msa_en_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate MSA to English: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W6j-SDXcNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"msa_en_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"msa_en_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=msa_en_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[msa_en_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path= filepath, #str(multibpemb.model_file), #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    num_input_examples=msa_en_example_count\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGr8wt7naDRL",
        "colab_type": "text"
      },
      "source": [
        "###Levantine to MSA Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3A3wQdjagH6",
        "colab": {}
      },
      "source": [
        "lav_msa_split_csv_path = {\n",
        "    \"train\": \"data/train/train_lav_msa.csv\",\n",
        "    \"validation\": \"data/val/val_lav_msa.csv\"\n",
        "}\n",
        "lav_msa_example_count = {\n",
        "    \"train\": 11044,\n",
        "    \"validation\": 2761\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3ee75e4-9d9c-432a-893d-18902fb20b5c",
        "id": "xCK_j-9BagH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def lav_msa_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(lav_msa_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(lav_msa_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b'\\xd8\\xa7\\xd9\\x84\\xd8\\xaa\\xd9\\x82\\xd9\\x89 \\xd8\\xa8\\xd8\\xa7\\xd8\\xa8\\xd9\\x86 \\xd8\\xb9\\xd9\\x85\\xd9\\x87 \\xd9\\x8a\\xd8\\xb9\\xd9\\x85\\xd9\\x84 \\xd9\\x85\\xd8\\xb9\\xd9\\x87 \\xd9\\x81\\xd9\\x8a \\xd8\\xa7\\xd9\\x84\\xd9\\x88\\xd9\\x84\\xd8\\xa7\\xd9\\x8a\\xd8\\xa9 \\xd9\\x82\\xd8\\xa7\\xd9\\x84 \\xd9\\x84\\xd9\\x87 \\xd8\\xa7\\xd9\\x8a\\xd9\\x86 \\xd8\\xaa\\xd8\\xb0\\xd9\\x87\\xd8\\xa8 \\xd9\\x82\\xd8\\xa7\\xd9\\x84 \\xd9\\x84\\xd9\\x87 \\xd8\\xa7\\xd8\\xb0\\xd9\\x87\\xd8\\xa8 \\xd9\\x84\\xd8\\xa7\\xd8\\xb9\\xd9\\x85\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd9\\x86 \\xd8\\xa7\\xd9\\x86\\xd8\\xa7 \\xd9\\x84\\xd8\\xa7 \\xd8\\xa7\\xd8\\xb9\\xd9\\x84\\xd9\\x85 \\xd8\\xb1\\xd8\\xa7\\xd9\\x87 \\xd8\\xb0\\xd9\\x84\\xd9\\x83 \\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd9\\x88\\xd9\\x85 \\xd8\\xa7\\xd9\\x85 \\xd9\\x81\\xd9\\x8a \\xd8\\xa7\\xd9\\x84\\xd8\\xba\\xd8\\xaf', 'target': b'\\xd8\\xb5\\xd8\\xaf\\xd9\\x81 \\xd8\\xa7\\xd8\\xa8\\xd9\\x86 \\xd8\\xb9\\xd9\\x85\\xd9\\x87 \\xd8\\xa8\\xd9\\x8a\\xd8\\xb4\\xd8\\xaa\\xd8\\xba\\xd9\\x84 \\xd9\\x85\\xd8\\xb9\\xd9\\x87 \\xd8\\xa8\\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd8\\xad\\xd8\\xa7\\xd9\\x81\\xd8\\xb8\\xd8\\xa9 \\xd9\\x82\\xd9\\x84\\xd9\\x87 \\xd9\\x88\\xd9\\x8a\\xd9\\x86 \\xd8\\xb1\\xd8\\xa7\\xd9\\x8a\\xd8\\xad \\xd9\\x82\\xd9\\x84\\xd9\\x87 \\xd8\\xb1\\xd8\\xa7\\xd9\\x8a\\xd8\\xad \\xd8\\xa7\\xd8\\xb4\\xd8\\xaa\\xd8\\xba\\xd9\\x84 \\xd8\\xa8\\xd8\\xb3 \\xd9\\x87\\xd9\\x84\\xd9\\x82 \\xd9\\x85\\xd8\\xa7 \\xd8\\xa8\\xd8\\xb9\\xd8\\xb1\\xd9\\x81 \\xd8\\xb4\\xd8\\xa7\\xd9\\x81\\xd9\\x87 \\xd8\\xa8\\xd9\\x86\\xd9\\x81\\xd8\\xb3 \\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd9\\x88\\xd9\\x85 \\xd9\\x88\\xd9\\x84\\xd8\\xa7 \\xd8\\xaa\\xd8\\xa7\\xd9\\x86\\xd9\\x8a \\xd9\\x8a\\xd9\\x88\\xd9\\x85'}\n",
            "{'source': b'\\xd8\\xad\\xd9\\x82\\xd8\\xa7', 'target': b'\\xd8\\xb9\\xd9\\x86\\xd8\\xac\\xd8\\xaf'}\n",
            "{'source': b'\\xd8\\xa7\\xd8\\xac\\xd9\\x84', 'target': b'\\xd8\\xa7\\xd9\\x8a'}\n",
            "{'source': b'\\xd8\\xb1\\xd8\\xa7\\xd9\\x8a\\xd8\\xaa\\xd9\\x87 \\xd9\\x8a\\xd8\\xb3\\xd8\\xaa\\xd8\\xb9\\xd9\\x85\\xd9\\x84 \\xd8\\xae\\xd9\\x8a\\xd8\\xb7\\xd8\\xa7 \\xd9\\x8a\\xd8\\xaf\\xd8\\xae\\xd9\\x84\\xd9\\x87 \\xd9\\x88 \\xd9\\x8a\\xd8\\xae\\xd8\\xb1\\xd8\\xac\\xd9\\x87', 'target': b'\\xd8\\xb4\\xd9\\x81\\xd8\\xaa\\xd9\\x88 \\xd8\\xb9\\xd9\\x85 \\xd9\\x8a\\xd8\\xad\\xd8\\xb7 \\xd9\\x8a\\xd8\\xae\\xd8\\xb7 \\xd9\\x8a\\xd8\\xaf\\xd8\\xae\\xd9\\x84\\xd9\\x88 \\xd9\\x88 \\xd9\\x8a\\xd8\\xb7\\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x88'}\n",
            "{'source': b'\\xd8\\xa7\\xd9\\x86\\xd9\\x89 \\xd8\\xa7\\xd8\\xb3\\xd9\\x85\\xd8\\xb9 \\xd9\\x87\\xd8\\xb0\\xd8\\xa7 \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x88\\xd8\\xb6\\xd9\\x88\\xd8\\xb9 \\xd9\\x84\\xd8\\xa7\\xd9\\x88\\xd9\\x84 \\xd9\\x85\\xd8\\xb1\\xd8\\xa9 \\xd9\\x88 \\xd8\\xa7\\xd8\\xb1\\xd8\\xac\\xd9\\x88 \\xd8\\xa7\\xd9\\x84\\xd8\\xa7 \\xd9\\x8a\\xd8\\xb2\\xd8\\xa7\\xd9\\x8a\\xd8\\xaf \\xd8\\xa7\\xd8\\xad\\xd8\\xaf \\xd8\\xb9\\xd9\\x84\\xd9\\x89 \\xd8\\xb4\\xd8\\xa8\\xd9\\x83 \\xd8\\xa7\\xd9\\x85 \\xd9\\x86\\xd8\\xa8\\xd9\\x8a\\xd9\\x84 \\xd9\\x88 \\xd8\\xa8\\xd8\\xb4\\xd9\\x83\\xd9\\x84 \\xd8\\xb9\\xd8\\xa7\\xd9\\x85 \\xd9\\x83\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd8\\xb4\\xd8\\xa8\\xd9\\x83\\xd8\\xa7\\xd8\\xaa \\xd8\\xa7\\xd8\\xb5\\xd8\\xa8\\xd8\\xad\\xd8\\xaa \\xd9\\x85\\xd8\\xab\\xd9\\x84 \\xd8\\xa8\\xd8\\xb9\\xd8\\xb6 \\xd9\\x88 \\xd9\\x83\\xd9\\x84\\xd9\\x87\\xd9\\x85 \\xd8\\xb3\\xd9\\x8a\\xd8\\xa6\\xd9\\x8a\\xd9\\x86', 'target': b'\\xd8\\xa7\\xd9\\x86\\xd8\\xa7 \\xd8\\xa7\\xd9\\x88\\xd9\\x84 \\xd9\\x85\\xd8\\xb1\\xd8\\xa9 \\xd8\\xa8\\xd8\\xb3\\xd9\\x85\\xd8\\xb9 \\xd8\\xb9\\xd9\\x86 \\xd9\\x87\\xd8\\xa7\\xd8\\xaf \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x88\\xd8\\xb6\\xd9\\x88\\xd8\\xb9 \\xd9\\x88\\xd9\\x85\\xd8\\xa7 \\xd8\\xad\\xd8\\xaf\\xd8\\xa7 \\xd9\\x8a\\xd8\\xba\\xd9\\x84\\xd8\\xb7 \\xd8\\xb9\\xd9\\x84\\xd9\\x89 \\xd9\\x85\\xd9\\x88\\xd9\\x82\\xd8\\xb9 \\xd8\\xa7\\xd9\\x85 \\xd9\\x86\\xd8\\xa8\\xd9\\x8a\\xd9\\x84 \\xd8\\xb9\\xd9\\x84\\xd9\\x89 \\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x85\\xd9\\x88\\xd9\\x85 \\xd9\\x83\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd9\\x88\\xd8\\xa7\\xd9\\x82\\xd8\\xb9 \\xd8\\xb5\\xd8\\xa7\\xd8\\xb1\\xd8\\xaa \\xd9\\x85\\xd8\\xb4 \\xd9\\x85\\xd9\\x86\\xd9\\x8a\\xd8\\xad\\xd8\\xa9 \\xd8\\xb2\\xd9\\x8a \\xd8\\xa8\\xd8\\xb9\\xd8\\xb6 '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fW9eNYoGagID",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def lav_msa_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate Levantine to MSA: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDoUsP1AagIG",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"lav_msa_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"lav_msa_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=lav_msa_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[lav_msa_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path= filepath, #str(multibpemb.model_file), #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    num_input_examples = lav_msa_example_count\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wIK8EWyaLFR",
        "colab_type": "text"
      },
      "source": [
        "###Maghrib to MSA Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bVhYmQnQaj2K",
        "colab": {}
      },
      "source": [
        "mag_msa_split_csv_path = {\n",
        "    \"train\": \"data/train/train_mag_msa.csv\",\n",
        "    \"validation\": \"data/val/val_mag_msa.csv\"\n",
        "}\n",
        "mag_msa_example_count = {\n",
        "    \"train\": 14188,\n",
        "    \"validation\": 3548\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b882ae68-968b-44dd-c868-231a5c0d8e1b",
        "id": "WBLF-J2Oaj2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "def mag_msa_translation_dataset_fn(split, shuffle_files=False):\n",
        "  ds = tf.data.TextLineDataset(mag_msa_split_csv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\",\"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  ds = ds.map(lambda *example: dict(zip([\"source\", \"target\"], example)) )\n",
        "  return ds\n",
        "\n",
        "for example in tfds.as_numpy(mag_msa_translation_dataset_fn(\"train\").take(5)):\n",
        "    print(example)\n",
        "    print(example['source'].decode())\n",
        "    print(example['target'].decode())\n",
        "    print(len(example['source']))\n",
        "    print(len(example['target']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'source': b' \\xd9\\x85\\xd8\\xb9\\xd8\\xb0\\xd8\\xb1\\xd8\\xa9 \\xd8\\xa7\\xd8\\xae\\xd9\\x8a \\xd9\\x84\\xd8\\xaf\\xd9\\x8a\\xd9\\x86\\xd8\\xa7 \\xd9\\x85\\xd8\\xa6\\xd8\\xb2\\xd8\\xb1 \\xd9\\x88\\xd8\\xa7\\xd8\\xad\\xd8\\xaf   ', 'target': b'\\xd8\\xa7\\xd8\\xb3\\xd9\\x85\\xd8\\xad \\xd9\\x84\\xd9\\x8a \\xd8\\xae\\xd9\\x88\\xd9\\x8a\\xd8\\xa7 \\xd8\\xb9\\xd9\\x86\\xd8\\xaf\\xd9\\x86\\xd8\\xa7 \\xd8\\xb7\\xd8\\xa8\\xd9\\x84\\xd9\\x8a\\xd8\\xa9 \\xd9\\x88\\xd8\\xad\\xd8\\xaf\\xd8\\xa9'}\n",
            " معذرة اخي لدينا مئزر واحد   \n",
            "اسمح لي خويا عندنا طبلية وحدة\n",
            "50\n",
            "53\n",
            "{'source': b'\\xd8\\xa8\\xd8\\xb9\\xd8\\xaf \\xd8\\xb0\\xd9\\x84\\xd9\\x83 \\xd8\\xa7\\xd8\\xb6\\xd8\\xb9\\xd9\\x87\\xd9\\x85 \\xd9\\x81\\xd9\\x8a \\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd9\\x83\\xd9\\x8a\\xd8\\xa7\\xd8\\xb3', 'target': b'\\xd8\\xa7\\xd9\\x88\\xd9\\x85\\xd8\\xa8\\xd8\\xb9\\xd8\\xaf \\xd9\\x86\\xd8\\xad\\xd8\\xb7\\xd9\\x87\\xd9\\x85 \\xd9\\x81\\xd9\\x8a \\xd9\\x84\\xd9\\x8a\\xd8\\xb3\\xd8\\xa7\\xd8\\xb4\\xd9\\x8a '}\n",
            "بعد ذلك اضعهم في الاكياس\n",
            "اومبعد نحطهم في ليساشي \n",
            "44\n",
            "42\n",
            "{'source': b' \\xd9\\x88 \\xd9\\x84\\xd9\\x85\\xd8\\xa7\\xd8\\xb0\\xd8\\xa7 \\xd9\\x8a\\xd8\\xa7 \\xd8\\xa7\\xd8\\xae\\xd8\\xaa\\xd9\\x8a \\xd9\\x83\\xd9\\x84 \\xd9\\x87\\xd8\\xb0\\xd8\\xa7   ', 'target': b'\\xd8\\xb9\\xd9\\x84\\xd8\\xa7\\xd8\\xb4 \\xd9\\x8a\\xd8\\xa7\\xd9\\x88\\xd8\\xae\\xd9\\x8a\\xd8\\xaa\\xd9\\x8a \\xd9\\x87\\xd8\\xb0\\xd8\\xa7 \\xd9\\x83\\xd9\\x84'}\n",
            " و لماذا يا اختي كل هذا   \n",
            "علاش ياوخيتي هذا كل\n",
            "43\n",
            "35\n",
            "{'source': b'\\xd8\\xa7\\xd8\\xb1\\xd8\\xa7\\xd9\\x8a\\xd8\\xaa \\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd9\\x85\\xd8\\xb7\\xd8\\xa7\\xd8\\xb1 \\xd9\\x81\\xd9\\x8a \\xd9\\x8a\\xd9\\x88\\xd9\\x85 \\xd9\\x88\\xd8\\xa7\\xd8\\xad\\xd8\\xaf \\xd8\\xaa\\xd9\\x85\\xd8\\xb1 \\xd8\\xa7\\xd9\\x84\\xd9\\x81\\xd8\\xb5\\xd9\\x88\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd8\\xb1\\xd8\\xa8\\xd8\\xb9\\xd8\\xa9', 'target': b'\\xd8\\xb4\\xd9\\x81\\xd8\\xaa \\xd8\\xa7\\xd9\\x84\\xd9\\x85\\xd8\\xb7\\xd8\\xb1 \\xd9\\x81\\xd9\\x8a \\xd9\\x86\\xd9\\x87\\xd8\\xa7\\xd8\\xb1 \\xd9\\x88\\xd8\\xa7\\xd8\\xad\\xd8\\xaf \\xd8\\xa7\\xd9\\x84\\xd9\\x81\\xd8\\xb5\\xd9\\x88\\xd9\\x84 \\xd8\\xa7\\xd9\\x84\\xd8\\xa7\\xd8\\xb1\\xd8\\xa8\\xd8\\xb9\\xd8\\xa9'}\n",
            "ارايت الامطار في يوم واحد تمر الفصول الاربعة\n",
            "شفت المطر في نهار واحد الفصول الاربعة\n",
            "81\n",
            "68\n",
            "{'source': b'\\xd8\\xb6\\xd8\\xad\\xd9\\x83\\xd8\\xaa \\xd9\\x83\\xd8\\xab\\xd9\\x8a\\xd8\\xb1\\xd8\\xa7 \\xd8\\xb9\\xd9\\x86\\xd8\\xaf\\xd9\\x85\\xd8\\xa7 \\xd8\\xb7\\xd9\\x84\\xd8\\xa8\\xd8\\xaa\\xd9\\x8a \\xd9\\x85\\xd9\\x86\\xd9\\x8a \\xd8\\xa7\\xd9\\x86 \\xd8\\xa7\\xd8\\xae\\xd8\\xa8\\xd8\\xb1\\xd9\\x87\\xd8\\xa7 \\xd8\\xb9\\xd9\\x86 \\xd8\\xb7\\xd8\\xb1\\xd9\\x8a\\xd9\\x82 \\xd8\\xa7\\xd9\\x84\\xd8\\xac\\xd9\\x88\\xd8\\xa7\\xd9\\x84', 'target': b'\\xd9\\x83\\xd9\\x8a\\xd9\\x81 \\xd9\\x82\\xd8\\xaa\\xd9\\x84\\xd9\\x8a \\xd9\\x86\\xd9\\x82\\xd9\\x84\\xd9\\x87\\xd8\\xa7 \\xd9\\x81\\xd9\\x8a \\xd8\\xaa\\xd9\\x84\\xd9\\x8a\\xd9\\x81\\xd9\\x88\\xd9\\x86 \\xd8\\xb4\\xd8\\xa8\\xd8\\xb9\\xd8\\xaa \\xd8\\xa8\\xd8\\xb6\\xd8\\xad\\xd9\\x83 '}\n",
            "ضحكت كثيرا عندما طلبتي مني ان اخبرها عن طريق الجوال\n",
            "كيف قتلي نقلها في تليفون شبعت بضحك \n",
            "93\n",
            "63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GgyqkGfYaj2Y",
        "colab": {}
      },
      "source": [
        "#turn the ds of dictionaries and change the keys to inputs and targets that the model\n",
        "def mag_msa_translation_preprocessor(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "    return{\n",
        "        \"inputs\": tf.strings.join([\"Translate Maghrib to Arabic: \",ex[\"source\"]]),\n",
        "        \"targets\": ex[\"target\"]\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bmja1M2Eaj2f",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"mag_msa_translation\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    #name of the Task\n",
        "    \"mag_msa_translation\",\n",
        "    #Supply a function which returns a tf.data.Dataset\n",
        "    dataset_fn=mag_msa_translation_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[mag_msa_translation_preprocessor],\n",
        "    # Use the same vocabulary that we used for pre-training.\n",
        "    sentencepiece_model_path=filepath, #t5.data.DEFAULT_SPM_PATH\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn = t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    num_input_examples = mag_msa_example_count\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLoe7vbFV42o",
        "colab_type": "text"
      },
      "source": [
        "##Dataset Mixture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMTtMsXWAua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.MixtureRegistry.remove(\"ar_translation\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"ar_translation\",\n",
        "    [\"msa_en_translation\", \"lav_msa_translation\", \"mag_msa_translation\"],\n",
        "     default_rate=1.0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc0bSgP1WenA",
        "colab_type": "text"
      },
      "source": [
        "##Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M23Y4l0tb4qM",
        "colab_type": "code",
        "outputId": "f81e54d6-281e-44ec-9322-f9602d159c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls /tmp/hft5"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/tmp/hft5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uP2fwStXK5b",
        "colab_type": "code",
        "outputId": "fa62f18f-2dba-4847-8810-de6719e001a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "cba37d0eaf7b477fb3ae31639892334d",
            "02b2a03df5f34193a0f898ee439e1998",
            "168d6a31e28340b592627f7003f6aef8",
            "f73bbc88e81c44ca8361bcc031fc5180",
            "e2bdb040fbad42bdbf657da77b620189",
            "6886f4b4b074409e9ec1468221355e85",
            "021be06d43b64a58b8170974a64d3dc2",
            "1a44c7ed3dfd46feaf4d32f00a20013e",
            "93fca8325042411886f249f49f7cb550",
            "bc1d12eb91a642949d0c5b624adf9029",
            "c48fe50578a14104b6a32141c9b9dda3",
            "a1160dc7d1b743289b33b977f4e1cc0b",
            "ea8eb069c7a54eccbaccc2b2270200ea",
            "ab558f8a8fed464ca7f3c6e1aef72e1c",
            "fa47591c8adc40148b945fa959fa95e1",
            "e0d6273386054b02ad52984614f5dbb8"
          ]
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "#Using the Huggingface T5 Model\n",
        "\n",
        "model = t5.models.HfPyTorchModel(\"t5-base\", \"/tmp/hft5/\", device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba37d0eaf7b477fb3ae31639892334d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93fca8325042411886f249f49f7cb550",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6f5uUWXWUKw",
        "colab_type": "code",
        "outputId": "ce413c9d-c451-4827-d912-1f99099b6fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "STEPS = 10000 #@param {type: \"integer\"}\n",
        "model.train(\n",
        "    mixture_or_task_name=\"ar_translation\",\n",
        "    steps=STEPS,\n",
        "    save_steps=1000,\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 128},\n",
        "    split=\"train\",\n",
        "    batch_size=32, #32\n",
        "    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Saving checkpoint for step 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-998314d9c506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mixture_or_task_name, steps, save_steps, sequence_length, split, batch_size, optimizer, learning_rate_scheduler)\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m           \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m           \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m       )\n\u001b[1;32m    330\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_past_key_value_states, use_cache, lm_labels, inputs_embeds, decoder_inputs_embeds, head_mask)\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             encoder_outputs = self.encoder(\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             )\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, past_key_value_states, use_cache)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You have to intialize the model with valid token embeddings\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev_E4ZadXxmj",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjZnTOIrYEh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate after fine-tuning\n",
        "model.eval(\n",
        "    \"ar_translation\",\n",
        "    checkpoint_steps=\"all\",\n",
        "    sequence_length={\"inputs\": 64, \"targets\": 64},\n",
        "    batch_size=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF-3_4u1X-5r",
        "colab_type": "text"
      },
      "source": [
        "##Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL5yLXs4YJw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = [\n",
        "    \"translation: This is a totally valid sentence.\",\n",
        "    \"translation: A doggy detail was walking famously.\",\n",
        "]\n",
        "model.predict(\n",
        "    inputs,\n",
        "    sequence_length={\"inputs\": 32},\n",
        "    batch_size=2,\n",
        "    output_file=\"/tmp/hft5/example_predictions.txt\",\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}